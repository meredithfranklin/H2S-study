---
title: "Data Modelling V2 202310"
author: "Jerry Wu"
date: "2024-09-08"
output:
  html_document:
    df_print: paged
  pdf_document: default
abstract: ''
subtitle: ''
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
library(tidyverse)
library(mgcv)
library(mgcViz)
library(caret)
library(xgboost)
library(fastDummies)
library(circular)
library(raster)
library(terra)
library(sf)
library(evgam)
library(ggpubr)
library(ggpmisc)
library(leaps)
library(kableExtra)
select <- dplyr::select
```

```{r}
#full_data <- readRDS('../data/full_data_20230930.rds')
hourly_full <- readRDS('../data/hourly_full_20230930.rds')
daily_full <- readRDS('../data/daily_full_20230930.rds')
```

# Explore some summary statistics
```{r}
daily_full <- daily_full %>%
  filter(!is.na(H2S_daily_avg))
hourly_full <- hourly_full %>%
  filter(!is.na(H2S_hourly_avg))
gc()
```

```{r}
# full_data <- full_data %>%
#   filter(!is.na(H2S)) %>%
#   select(-starts_with('daily_'), -starts_with('H2S_daily'), 
#          -all_of(c('Ammonia', 'Benzene', 'Black Carbon', 'DST', 'utm_x', 'utm_y',
#                    'county')))
# gc()
```


## Fixed Monitor stats
```{r}
monitor_names <- c("ElSegundo" = "El Segundo", 
                   "StAnthony" = "St. Anthony",
                   "Manhattan" = "Manhattan",
                   "WestHS" = "West HS",
                   "ElmAve" = "Elm Ave",
                   "NorthHS" = "North HS",
                   "GuenserPark" = "Guenser Park",
                   "Chico" = "213th & Chico",
                   "Judson" = "Judson",
                   "HarborPark" = "Harbor Park",
                   "FirstMethodist" = "First Methodist",
                   "GStreet" = "G Street",
                   "StLuke" = "St. Luke",
                   "Hudson" = "Hudson",
                   "InnerPort" = "Inner Port")

base_monitor_stat <- daily_full %>%
  group_by(Monitor) %>%
  summarise('Start Date' = strftime(min(day), '%Y-%m-%d'),
            'End Date' = strftime(max(day), '%Y-%m-%d'),
            'Closest Refinery' = unique(closest_ref),
            'Distance to Nearest Refinery (m)' = round(unique(dist_ref)),
            'Angle to Refinery' = unique(angle_ref),
            'Distance to Nearest WRP (m)' = round(unique(dist_wrp)),
            'Capacity of Nearest WRP' = unique(closest_wrp_capacity),
            'Angle to WRP' = round(unique(angle_wrp)),
            'Distance to Dominguez Channel (m)' = round(unique(dist_dc)),
            'Elevation' = unique(elevation),
            'Enhanced Vegetation Index' = unique(EVI)) %>%
  mutate(`Closest Refinery` = case_when(`Closest Refinery` == "Phillips 66 (Wilmington)" ~ "Phillips 66",
                                        `Closest Refinery` == "Torrance Refinery" ~ "Torrance",
                                        `Closest Refinery` == "Valero Refinery" ~ "Valero",
                                        `Closest Refinery` == "Marathon (Carson)" ~ "Marathon Carson",
                                        `Closest Refinery` == "Marathon (Wilmington)" ~ "Marathon Wilmington",
                                        .default = `Closest Refinery`)) %>%
  mutate(Monitor = str_replace_all(Monitor, monitor_names)) %>%
  arrange(factor(Monitor, levels = unname(monitor_names)))

knitr::kable(base_monitor_stat, digits = 2, format = 'html')
```

## Since Feb 2022
```{r}
sincefeb2022_stat <- daily_full %>%
  filter(day > '2022-01-31') %>%
  group_by(Monitor) %>%
  summarise('Daily observations' = n(),
            'Max Daily Max' = max(H2S_daily_max, na.rm=T),
            'Max Daily Average' = max(H2S_daily_avg, na.rm=T),
            'Avg Daily Max' = mean(H2S_daily_max, na.rm=T),
            'Avg Daily Average' = mean(H2S_daily_avg, na.rm=T),
            'Average Wind Speed' = mean(ws_avg, na.rm=T),
            'Average Wind Direction' = as.numeric(mean(circular(wd_avg, 
                                                                units = 'degrees'), 
                                                       na.rm=T)),
            'Average daily odor complaints within county' = mean(num_odor_complaints, na.rm=T),
            'Active wells 2km' = mean(active_2km, na.rm=T)) %>%
  mutate('Average Wind Direction' = if_else(`Average Wind Direction` < 0, 
                                            `Average Wind Direction`+360, 
                                            `Average Wind Direction`)) %>%
  mutate(Monitor = str_replace_all(Monitor, monitor_names)) %>%
  arrange(factor(Monitor, levels = unname(monitor_names)))

knitr::kable(sincefeb2022_stat, digits = 2, format = 'html')
```

## During Disaster (October 2021 - December 2021)
```{r}
disaster_stat <- daily_full %>%
  filter(year == '2021', month %in% c('10', '11', '12')) %>%
  group_by(Monitor) %>%
  summarise('Daily observations' = n(),
            'Max Daily Max' = max(H2S_daily_max, na.rm=T),
            'Max Daily Average' = max(H2S_daily_avg, na.rm=T),
            'Avg Daily Max' = mean(H2S_daily_max, na.rm=T),
            'Avg Daily Average' = mean(H2S_daily_avg, na.rm=T),
            'Average Wind Speed' = mean(ws_avg, na.rm=T),
            'Average Wind Direction' = as.numeric(mean(circular(wd_avg, 
                                                                units = 'degrees'), 
                                                       na.rm=T)),
            'Average daily odor complaints within county' = mean(num_odor_complaints, na.rm=T),
            'Active wells 2km' = mean(active_2km, na.rm=T)) %>%
  mutate('Average Wind Direction' = if_else(`Average Wind Direction` < 0, 
                                            `Average Wind Direction`+360, 
                                            `Average Wind Direction`)) %>%
  mutate(Monitor = str_replace_all(Monitor, monitor_names)) %>%
  arrange(factor(Monitor, levels = unname(monitor_names)))

knitr::kable(disaster_stat, digits = 2, format = 'html')
```

```{r}
# Try only the october for the prediction map
disaster_oct_stat <- daily_full %>%
  filter(year == '2021', month == '10') %>%
  group_by(Monitor) %>%
  summarise('Daily observations' = n(),
            'Max Daily Max' = max(H2S_daily_max, na.rm=T),
            'Max Daily Average' = max(H2S_daily_avg, na.rm=T),
            'Avg Daily Max' = mean(H2S_daily_max, na.rm=T),
            'Avg Daily Average' = mean(H2S_daily_avg, na.rm=T),
            'Average Wind Speed' = mean(ws_avg, na.rm=T),
            'Average Wind Direction' = as.numeric(mean(circular(wd_avg, 
                                                                units = 'degrees'), 
                                                       na.rm=T)),
            'Average daily odor complaints within county' = mean(num_odor_complaints, na.rm=T),
            'Active wells 2km' = mean(active_2km, na.rm=T)) %>%
  mutate('Average Wind Direction' = if_else(`Average Wind Direction` < 0, 
                                            `Average Wind Direction`+360, 
                                            `Average Wind Direction`)) %>%
  mutate(Monitor = str_replace_all(Monitor, monitor_names)) %>%
  arrange(factor(Monitor, levels = unname(monitor_names)))

knitr::kable(disaster_oct_stat, digits = 2, format = 'html')
```

## Normal Period (Jan 2020- May 2023) excluding disaster
```{r}
normal_stat <- daily_full %>%
  filter(!(year == '2021' & month %in% c('10', '11', '12'))) %>%
  group_by(Monitor) %>%
  summarise('Daily observations' = n(),
            'Max Daily Max' = max(H2S_daily_max, na.rm=T),
            'Max Daily Average' = max(H2S_daily_avg, na.rm=T),
            'Avg Daily Max' = mean(H2S_daily_max, na.rm=T),
            'Avg Daily Average' = mean(H2S_daily_avg, na.rm=T),
            'Average Wind Speed' = mean(ws_avg, na.rm=T),
            'Average Wind Direction' = as.numeric(mean(circular(wd_avg, 
                                                                units = 'degrees'), 
                                                       na.rm=T)),
            'Average daily odor complaints within county' = mean(num_odor_complaints, na.rm=T),
            'Active wells 2km' = mean(active_2km, na.rm=T)) %>%
  mutate('Average Wind Direction' = if_else(`Average Wind Direction` < 0, 
                                            `Average Wind Direction`+360, 
                                            `Average Wind Direction`)) %>%
  mutate(Monitor = str_replace_all(Monitor, monitor_names)) %>%
  arrange(factor(Monitor, levels = unname(monitor_names)))

knitr::kable(normal_stat, digits = 2, format = 'html')
```

```{r}
# Try only the Oct 2022
normal_oct_stat <- daily_full %>%
  filter(year == '2022' & month == '10') %>%
  group_by(Monitor) %>%
  summarise('Daily observations' = n(),
            'Max Daily Max' = max(H2S_daily_max, na.rm=T),
            'Max Daily Average' = max(H2S_daily_avg, na.rm=T),
            'Avg Daily Max' = mean(H2S_daily_max, na.rm=T),
            'Avg Daily Average' = mean(H2S_daily_avg, na.rm=T),
            'Average Wind Speed' = mean(ws_avg, na.rm=T),
            'Average Wind Direction' = as.numeric(mean(circular(wd_avg, 
                                                                units = 'degrees'), 
                                                       na.rm=T)),
            'Average daily odor complaints within county' = mean(num_odor_complaints, na.rm=T),
            'Active wells 2km' = mean(active_2km, na.rm=T)) %>%
  mutate('Average Wind Direction' = if_else(`Average Wind Direction` < 0, 
                                            `Average Wind Direction`+360, 
                                            `Average Wind Direction`)) %>%
  mutate(Monitor = str_replace_all(Monitor, monitor_names)) %>%
  arrange(factor(Monitor, levels = unname(monitor_names)))

knitr::kable(normal_oct_stat, digits = 2, format = 'html')
```

## Table 1: Monitor statistics
```{r}
table1 <- base_monitor_stat %>%
  select(-c(`Angle to Refinery`, `Angle to WRP`, `Capacity of Nearest WRP`)) %>%
  left_join(disaster_stat %>% 
              select(Monitor, `Avg Daily Average`) %>% 
              rename(`Disaster Avg Daily Average` = `Avg Daily Average`), 
            join_by(Monitor)) %>%
  left_join(normal_stat %>% 
              select(Monitor, `Avg Daily Average`) %>%
              rename(`Normal Avg Daily Average` = `Avg Daily Average`), 
            join_by(Monitor)) %>%
  relocate(Monitor, `Start Date`, `End Date`, `Closest Refinery`, `Normal Avg Daily Average`, `Disaster Avg Daily Average`)

table1_kable <- knitr::kable(table1, format = 'latex', digits = 2)
writeLines(table1_kable, '../figures/table1.tex')

knitr::kable(table1, format = 'html', digits = 2)
```


# GAM
## Feature Selection
### Prepare feature and data tables
```{r}
hourly_responses <- c('H2S_hourly_avg', 'H2S_hourly_max')

# since feb 2022
daily_data_sincefeb2022 <- daily_full %>% filter(day > '2022-01-31')
hourly_data_sincefeb2022 <- hourly_full %>% filter(day > '2022-01-31')

# Disaster
daily_data_dis <- daily_full %>% filter(year == '2021', month %in% c('10', '11', '12'))
hourly_data_dis <- hourly_full %>% filter(year == '2021', month %in% c('10', '11', '12'))

# Exclude disaster stepwise
daily_data_excl_dis <- daily_full %>% filter(!(year == '2021' & month %in% c('10', '11', '12')))
hourly_data_excl_dis <- hourly_full %>% filter(!(year == '2021' & month %in% c('10', '11', '12')))

# Everything w. disaster indicator
daily_data_dis_ind <- daily_full %>% 
  mutate(disaster = 
           if_else(year == '2021', month %in% c('10', '11', '12'), 1, 0))
hourly_data_dis_ind <- hourly_full %>% 
  mutate(disaster = 
           if_else(year == '2021', month %in% c('10', '11', '12'), 1, 0))
```

### Select smooth
```{r}
daily_responses <- c('H2S_daily_avg', 'log(H2S_daily_avg)', 
                     'H2S_daily_max', 'log(H2S_daily_max)')
hourly_responses <- c('H2S_hourly_avg', 'log(H2S_hourly_avg)',
                      'H2S_hourly_max', 'log(H2S_hourly_max)')
dateranges <- c('sincefeb2022', 'dis', 'excl_dis', 'dis_ind', 'full')
smooth <- c("s(as.numeric(month),bs='cc')", 
            "s(I(mon_utm_x/10^3), I(mon_utm_y/10^3), bs='tp', k = 10)",
            "te(I(mon_utm_x/10^3), I(mon_utm_y/10^3), as.numeric(day), k=c(10,10),d=c(2,1),bs=c('tp','cc'))")
smooth_tibble <- tibble(features = c(list(c(smooth[1])), 
                                     list(c(smooth[2])),
                                     list(c(smooth[3])),
                                     list(c(smooth[1:2])),
                                     list(c(smooth[c(1, 3)])),
                                     list(c(smooth[2:3])),
                                     list(c(smooth[1:3]))),
                        disaster_applicable = c(0, 1, 1, 0, 0, 1, 0))
# smooth_compare <- crossing(response = c(daily_responses, hourly_responses), 
#                            daterange = dateranges) %>%
#   cross_join(smooth_tibble) %>%
#   mutate(GCV = NA) %>%
#   filter(!(daterange == 'dis' & disaster_applicable == 0)) %>%
#   select(-disaster_applicable)
# 
# for (i in 89:nrow(smooth_compare)) {
#   features <- unname(unlist(smooth_compare[i,'features']))
#   formula_feature_str <- paste(features, collapse = ' + ')
#   formula_str <- paste(smooth_compare[[i, 'response']], formula_feature_str, sep = ' ~ ')
#   formula <- as.formula(formula_str)
# 
#   if (smooth_compare[[i, 'response']] %in% hourly_responses &
#       smooth_compare[[i, 'daterange']] == 'full') {
#     data <- hourly_full
#   } else if (smooth_compare[[i, 'response']] %in% hourly_responses){
#     data <- get(paste0('hourly_data_', smooth_compare[[i, 'daterange']]))
#   } else if (smooth_compare[[i, 'daterange']] == 'full') {
#     data <- daily_full
#   } else {
#     data <- get(paste0('daily_data_', smooth_compare[[i, 'daterange']]))
#   }
# 
#   summary <- summary(gam(formula, data = data, method = 'GCV.Cp', select = TRUE))
#   GCV_new <- summary$sp.criterion[[1]]
#   smooth_compare[i, 'GCV'] <- GCV_new
#   print(str_glue('Completed {i} iterations'))
#   gc()
# }
# 
# smooth_compare <- smooth_compare %>%
#   group_by(response, daterange) %>%
#   mutate(best = if_else(GCV == min(GCV), 1, 0)) %>%
#   mutate(rounded_GCV = round(GCV, 2)) %>%
#   rowwise() %>%
#   mutate(month_smooth = if_else(smooth[1] %in% unlist(features), 1, 0),
#          coord_smooth = if_else(smooth[2] %in% unlist(features), 1, 0),
#          coord_day_3D_smooth = if_else(smooth[3] %in% unlist(features), 1, 0)) %>%
#   ungroup()
# saveRDS(smooth_compare, 'smooth_compare.rds')

smooth_compare <- readRDS('smooth_compare.rds')
```

```{r}
# get best smooth models for diff response and daterange
best_smooth <- smooth_compare %>%
  group_by(response, daterange) %>%
  filter(GCV == min(GCV)) %>%
  ungroup() %>%
  select(response, daterange, GCV, features, month_smooth, coord_smooth, coord_day_3D_smooth)
best_smooth
```

- In general, having the coordinate smooth on top of the month and 3D smooth will not harm the model (except for daily max models since feb 2022). 
- However, it does not improve it by much either...
- We will keep this in. 

### Fit smooth and get Residuals
```{r}
response_names <- c('da', 'log_da', 'dm', 'log_dm', 'ha', 'log_ha', 'hm', 'log_hm')

# smooth_models <- tibble(name = response_names,
#                         response = responses) %>%
#   crossing(daterange) %>%
#   mutate(name = paste(name, daterange, sep = '_'))


smooth_predictors <-
  c("s(as.numeric(month),bs='cc')",
    "s(I(mon_utm_x/10^3), I(mon_utm_y/10^3), bs='tp', k = 10)",
    "te(I(mon_utm_x/10^3), I(mon_utm_y/10^3), as.numeric(day), k=c(10,10),d=c(2,1),bs=c('tp','cc'))")
# 
# smooth_models$residuals <- rep(list(c()), nrow(smooth_models))
# 
# for (i in 1:nrow(smooth_models)) {
#   # first, get residuals of smooth on response
#   if (smooth_models$daterange[i] == 'dis') {
#     formula_feature_str <- paste(smooth_predictors[c(2, 3)], collapse = ' + ')
#   } else {
#     formula_feature_str <- paste(smooth_predictors, collapse = ' + ')
#   }
# 
#   if (smooth_models[[i, 'response']] %in% hourly_responses &
#       smooth_models[[i, 'daterange']] == 'full') {
#     data <- hourly_full
#   } else if (smooth_models[[i, 'response']] %in% hourly_responses) {
#     data <- get(paste0('hourly_data_', smooth_models[[i, 'daterange']]))
#   } else if (smooth_models[[i, 'daterange']] == 'full') {
#     data <- daily_full
#   } else {
#     data <- get(paste0('daily_data_', smooth_models[[i, 'daterange']]))
#   }
# 
#   formula_str <- paste(smooth_models[[i, 'response']], formula_feature_str, sep = ' ~ ')
#   formula <- as.formula(formula_str)
#   residuals <- gam(formula, data = data, method = 'GCV.Cp')$residuals
#   smooth_models$residuals[i] <- list(residuals)
# }
# saveRDS(smooth_models, 'smooth_models.rds')

smooth_models <- readRDS('smooth_models.rds')
```

### Fit residuals to select linear features
```{r, message = FALSE}
disaster_predictors <- c('month', 'weekday', 'wd_avg', 'ws_avg', 
                       'I(1/dist_wrp^2)', 'I(1/dist_ref^2)', 'I(1/dist_dc^2)',
                       'monthly_oil_2km', 'monthly_gas_2km', 'active_2km', 
                       'inactive_2km', 'elevation', 'EVI', 
                       'num_odor_complaints', 'closest_wrp_capacity')

everything_predictors <- c('year', 'weekday', 'wd_avg', 'ws_avg', 
                       'I(1/dist_wrp^2)', 'I(1/dist_ref^2)', 'I(1/dist_dc^2)',
                       'monthly_oil_2km', 'monthly_gas_2km', 'active_2km', 
                       'inactive_2km', 'elevation', 'EVI', 
                       'num_odor_complaints', 'closest_wrp_capacity')

daily_predictors <- c('daily_downwind_ref', 'daily_downwind_wrp', 'daily_temp',
                      'daily_hum', 'daily_precip')

hourly_predictors <- c('hourly_downwind_ref', 'hourly_downwind_wrp', 'hourly_temp',
                      'hourly_hum', 'hourly_precip')

disaster_linear_pred_str <- paste(disaster_predictors, collapse = ' + ')
everything_linear_pred_str <- paste(everything_predictors, collapse = ' + ')
daily_linear_pred_str <- paste(daily_predictors, collapse = ' + ')
hourly_linear_pred_str <- paste(hourly_predictors, collapse = ' + ')

# for (i in 1:nrow(smooth_models)) {
#   if (smooth_models[[i, 'daterange']] == 'dis_ind' &
#       smooth_models[[i, 'response']] %in% hourly_responses) {
#     formula_str <- paste(everything_linear_pred_str,
#                          hourly_linear_pred_str,
#                          'disaster', sep = ' + ')
#   } else if (smooth_models[[i, 'daterange']] == 'dis' &
#              smooth_models[[i, 'response']] %in% hourly_responses) {
#     formula_str <- paste(disaster_linear_pred_str,
#                          hourly_linear_pred_str, sep = ' + ')
#   } else if (smooth_models[[i, 'response']] %in% hourly_responses) {
#     formula_str <- paste(everything_linear_pred_str,
#                          hourly_linear_pred_str, sep = ' + ')
#   } else if (smooth_models[[i, 'daterange']] == 'dis_ind') {
#     formula_str <- paste(everything_linear_pred_str,
#                          daily_linear_pred_str,
#                          'disaster', sep = ' + ')
#   } else if (smooth_models[[i, 'daterange']] == 'dis') {
#     formula_str <- paste(disaster_linear_pred_str,
#                          daily_linear_pred_str, sep = ' + ')
#   } else {
#     formula_str <- paste(everything_linear_pred_str,
#                          daily_linear_pred_str, sep = ' + ')
#   }
#   formula_str <- paste('residuals', formula_str, sep = ' ~ ')
#   formula <- as.formula(formula_str)
# 
#   if (smooth_models[[i, 'response']] %in% hourly_responses &
#       smooth_models[[i, 'daterange']] == 'full') {
#     data <- hourly_full
#   } else if (smooth_models[[i, 'response']] %in% hourly_responses){
#     data <- get(paste0('hourly_data_', smooth_models[[i, 'daterange']]))
#   } else if (smooth_models[[i, 'daterange']] == 'full') {
#     data <- daily_full
#   } else {
#     data <- get(paste0('daily_data_', smooth_models[[i, 'daterange']]))
#   }
# 
#   data$residuals <- unlist(smooth_models$residuals[i])
#   regsubsets <- regsubsets(formula, data, nvmax = Inf)
#   assign(paste0(smooth_models$name[i], '_regsubsets'), regsubsets)
#   print(str_glue('Completed {i} rows'))
# }
# 
# for (i in 1:nrow(smooth_models)) {
#   saveRDS(get(paste0(smooth_models$name[i], '_regsubsets')),
#           paste0('regsubsets/', smooth_models$name[i], '_regsubsets.rds'))
# }

# read regsubsets
for (i in 1:nrow(smooth_models)) {
  assign(paste0(smooth_models$name[i], '_regsubsets'),
         readRDS(paste0('regsubsets/', smooth_models$name[i], '_regsubsets.rds')))
}
```


<!-- ```{r} -->
<!-- # prepare stepwise function -->
<!-- # for this function, I will first have the set of features -->
<!-- # at each step, find the variable to add/remove that improves model the most -->
<!-- # using the GCV score (lower = better) -->
<!-- get_best_feature_forward <- function(response, used_features, unused_features, data) { -->
<!--     print('Adding...') -->
<!--     if (length(unused_features) > 0) { -->
<!--       change_GCV_forward <- tibble(feature = unused_features,  -->
<!--                            GCV_new = NA) -->
<!--       for (feature in unused_features) { -->
<!--         new_features <- c(used_features, feature) -->
<!--         formula_feature_str <- paste(new_features, collapse = ' + ') -->
<!--         formula_str <- paste(response, formula_feature_str, sep = ' ~ ') -->
<!--         print(formula_str) -->
<!--         formula <- as.formula(formula_str) -->

<!--         gam_model <- gam(formula, data = data, method = 'GCV.Cp', select = TRUE) -->
<!--         summary <- summary(gam_model) -->

<!--         # get the GCV of new model -->
<!--         GCV_new <- summary$sp.criterion[[1]] -->
<!--         print(GCV_new) -->
<!--         change_GCV_forward$GCV_new[change_GCV_forward$feature == feature] <- GCV_new -->
<!--       } -->
<!--       best_feature_forward <- change_GCV_forward[which(change_GCV_forward$GCV_new == -->
<!--                                                          min(change_GCV_forward$GCV_new)), ] -->
<!--       best_feature_forward <- best_feature_forward[1, ] -->
<!--     } else if (length(unused_features) == 0) { -->
<!--       # no more feature to add so always prefer current model or backward -->
<!--       best_feature_forward <- tibble(feature = 'FULLMODEL', GCV_new = Inf) -->
<!--     } else { -->
<!--       # no more feature to add in stepwise -->
<!--       # backward should compare to last model -->
<!--       best_feature_forward <- tibble(feature = NA, GCV_new = GCV) -->
<!--     } -->
<!--   return(best_feature_forward) -->
<!-- } -->

<!-- get_best_feature_backward <- function(response, used_features, unused_features, data) { -->
<!--     print('Removing...') -->
<!--     if (length(used_features) > 1) { -->
<!--       change_GCV_backward <- tibble(feature = used_features,  -->
<!--                                     GCV_new = NA) -->
<!--       for (feature in used_features) { -->
<!--         formula_feature_str <- paste(setdiff(used_features, feature), collapse = ' + ') -->
<!--         formula_str <- paste(response, formula_feature_str, sep = ' ~ ') -->
<!--         print(formula_str) -->
<!--         formula <- as.formula(formula_str) -->

<!--         gam_model <- gam(formula, data = data, method = 'GCV.Cp', select = TRUE) -->
<!--         summary <- summary(gam_model) -->

<!--         # get the GCV of new model -->
<!--         GCV_new <- summary$sp.criterion[[1]] -->
<!--         print(GCV_new) -->
<!--         change_GCV_backward$GCV_new[change_GCV_backward$feature == feature] <- GCV_new -->
<!--       } -->
<!--       best_feature_backward <- change_GCV_backward[which(change_GCV_backward$GCV_new == -->
<!--                                                            min(change_GCV_backward$GCV_new)), ] -->
<!--       best_feature_backward <- best_feature_backward[1, ] -->
<!--     } else if (length(used_features) == 1) { -->
<!--       # only one feature left to remove, which gives intercept model -->
<!--         formula_str <- paste(response, '1', sep = ' ~ ') -->

<!--         print(formula_str) -->
<!--         formula <- as.formula(formula_str) -->

<!--         gam_model <- gam(formula, data = data, method = 'GCV.Cp', select = TRUE) -->
<!--         summary <- summary(gam_model) -->

<!--         # get the GCV of new model -->
<!--         GCV_new <- summary$sp.criterion[[1]] -->
<!--         print(GCV_new) -->
<!--         best_feature_backward <- tibble(feature = 'Intercept', GCV_new = GCV_new) -->
<!--     } else { -->
<!--       # no feature to remove so always prefer last model or forward -->
<!--        best_feature_backward <- tibble(feature = NA, GCV_new = Inf) -->
<!--     } -->
<!--   return(best_feature_backward) -->
<!-- } -->

<!-- get_init_gcv <- function(response, used_features, unused_features, data) { -->
<!--   if (length(used_features) == 0) {used_features <- c('1')} -->
<!--   formula_feature_str <- paste(used_features, collapse = ' + ') -->
<!--   formula_str <- paste(response, formula_feature_str, sep = ' ~ ') -->
<!--   formula <- as.formula(formula_str) -->

<!--   # use select = TRUE to add penalty to null space (zero wiggliness) -->
<!--   # so smooth term can be penalized to zero instead of linear -->
<!--   gam_model <- gam(formula, data = data, method = 'GCV.Cp', select = TRUE) -->
<!--   summary <- summary(gam_model) -->

<!--   # get the GCV of init model -->
<!--   GCV <- summary$sp.criterion[[1]] -->
<!--   print(paste0('Starting GCV: ', GCV)) -->
<!--   return(GCV) -->
<!-- } -->

<!-- step_gam <- function(response, features, init_features, direction, data) { -->
<!--   step_i <- 1 -->
<!--   convergence <- FALSE -->
<!--   used_features <- init_features -->
<!--   unused_features <- setdiff(features, init_features) -->

<!--   GCV <- get_init_gcv(response, used_features, unused_features, data) -->

<!--   step_summary <- setNames(c(GCV, features %in% used_features), c("GCV", features)) -->
<!--   step_summary <- as_tibble(t(step_summary)) -->

<!--   i <- 1 -->
<!--   # until we reach convergence (GCV no longer decreases) -->
<!--   while (convergence == FALSE) { -->
<!--     print(paste0('Currently at ',i, ' iteration...')) -->
<!--     # forward selection -->
<!--     if (direction %in% c('forward', 'stepwise')) { -->
<!--       best_feature_forward <- get_best_feature_forward(response, used_features,  -->
<!--                                                        unused_features, data) -->
<!--     } -->

<!--     # backward selection -->
<!--     if (direction %in% c('backward', 'stepwise')) { -->
<!--       best_feature_backward <- get_best_feature_backward(response, used_features,  -->
<!--                                                          unused_features, data) -->
<!--     } -->

<!--     if (direction == 'forward') { -->
<!--       # compare the best feature to add with current GCV -->
<!--       if (best_feature_forward$GCV_new <= GCV) { -->
<!--         # add this feature to used feature vector and remove from unused -->
<!--         used_features <- append(used_features, best_feature_forward$feature) -->
<!--         unused_features <- setdiff(unused_features, best_feature_forward$feature) -->
<!--         GCV <- best_feature_forward$GCV_new # update GCV -->
<!--       } else { -->
<!--         convergence == TRUE -->
<!--         break -->
<!--       } -->
<!--     } else if (direction == 'backward') { -->
<!--       if (best_feature_backward$GCV_new <= GCV) { -->
<!--         # if this is intercept model and adding anything won't improve the model -->
<!--         if (best_feature_backward$feature == 'Intercept') { -->
<!--           convergence == TRUE -->
<!--         } -->
<!--         # add this feature to unused feature vector and remove from used -->
<!--         unused_features <- append(unused_features, best_feature_backward$feature) -->
<!--         used_features <- setdiff(used_features, best_feature_backward$feature) -->
<!--         GCV <- best_feature_backward$GCV_new # update GCV -->
<!--       } else { -->
<!--         convergence == TRUE -->
<!--         break -->
<!--       } -->
<!--     } else if (direction == 'stepwise') { -->
<!--       # for this, need compare both directions -->
<!--       # choose direction/feature that decreases GCV the most -->
<!--       if (best_feature_forward$GCV_new < best_feature_backward$GCV_new) { -->
<!--         # if forward is better (lower GCV) -->
<!--         if (best_feature_forward$GCV_new <= GCV) { -->
<!--           used_features <- append(used_features, best_feature_forward$feature) -->
<!--           unused_features <- setdiff(unused_features, best_feature_forward$feature) -->
<!--           GCV <- best_feature_forward$GCV_new -->
<!--         } else { -->
<!--           convergence == TRUE -->
<!--         break -->
<!--         } -->
<!--       } else if (best_feature_forward$GCV_new == best_feature_backward$GCV_new) { -->
<!--         # randomly choose step -->
<!--         random_coin <- sample(c(1, 2), 1) -->
<!--         if (random_coin == 1) { -->
<!--           if (best_feature_forward$GCV_new < GCV) { -->
<!--           # add this feature to used feature vector and remove from unused -->
<!--             used_features <- append(used_features, best_feature_forward$feature) -->
<!--             unused_features <- setdiff(unused_features, best_feature_forward$feature) -->
<!--             GCV <- best_feature_forward$GCV_new # update GCV -->
<!--           } -->
<!--         } else { -->
<!--             if (best_feature_backward$GCV_new < GCV) { -->
<!--               # if this is intercept model and adding anything won't improve the model -->
<!--               if (best_feature_backward$feature == 'Intercept') { -->
<!--                 convergence == TRUE -->
<!--               } -->
<!--               # add this feature to unused feature vector and remove from used -->
<!--               unused_features <- append(unused_features, best_feature_backward$feature) -->
<!--               used_features <- setdiff(used_features, best_feature_backward$feature) -->
<!--               GCV <- best_feature_backward$GCV_new # update GCV -->
<!--             } -->
<!--           } -->
<!--       } else { -->
<!--         # else backward is better -->
<!--         # if this new model gives better GCV than last model -->
<!--         if (best_feature_backward$GCV_new <= GCV) { -->
<!--           # if this is intercept model and adding anything won't improve the model -->
<!--           if (best_feature_backward$feature == 'Intercept') { -->
<!--             convergence == TRUE -->
<!--           } -->
<!--           # add this feature to unused feature vector and remove from used -->
<!--           unused_features <- append(unused_features, best_feature_backward$feature) -->
<!--           used_features <- setdiff(used_features, best_feature_backward$feature) -->
<!--           GCV <- best_feature_backward$GCV_new # update GCV -->
<!--         } else { -->
<!--           convergence == TRUE -->
<!--           break -->
<!--         } -->
<!--       } -->
<!--     } -->

<!--     # update step summary -->
<!--     new_step_summary <- setNames(c(GCV, rep(TRUE, length(used_features))), c("GCV", used_features)) -->
<!--     new_step_summary <- as_tibble(t(new_step_summary)) -->
<!--     step_summary <- bind_rows(step_summary, new_step_summary) -->

<!--     i <- i + 1 -->
<!--   } -->
<!--   step_summary[is.na(step_summary)] <- 0 -->
<!--   return(step_summary) -->
<!-- } -->
<!-- ``` -->

<!-- Daily Avg -->
<!-- ```{r} -->
<!-- # since feb 2022 stepwise -->
<!-- # da_step_gam_table_empty_init_sincefeb2022 <-  -->
<!-- #   step_gam('H2S_daily_avg', predictors_sincefeb2022, c(), 'stepwise', data_sincefeb2022) -->
<!-- # da_step_gam_table_full_init_sincefeb2022 <-  -->
<!-- #   step_gam('H2S_daily_avg', predictors_sincefeb2022, predictors_sincefeb2022, 'stepwise', data_sincefeb2022) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Disaster stepwise -->
<!-- # da_step_gam_table_empty_init_dis <- -->
<!-- #   step_gam('H2S_daily_avg', predictors_dis, c(), 'stepwise', data_dis) -->
<!-- # da_step_gam_table_full_init_dis <-  -->
<!-- #   step_gam('H2S_daily_avg', predictors_dis, predictors_dis, 'stepwise', data_dis) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Exclude disaster stepwise -->
<!-- # da_step_gam_table_empty_init_excl_dis <-  -->
<!-- #   step_gam('H2S_daily_avg', predictors_excl_dis, c(), 'stepwise', data_excl_dis) -->
<!-- # da_step_gam_table_full_init_excl_dis <-  -->
<!-- #   step_gam('H2S_daily_avg', predictors_excl_dis, predictors_excl_dis, 'stepwise', data_excl_dis) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # full with disaster indicator -->
<!-- # da_step_gam_table_empty_init_dis_ind <-  -->
<!-- #   step_gam('H2S_daily_avg', predictors_dis_ind, c(), 'stepwise', data_dis_ind) -->
<!-- # da_step_gam_table_full_init_dis_ind <-  -->
<!-- #   step_gam('H2S_daily_avg', predictors_dis_ind, predictors_dis_ind, 'stepwise', data_dis_ind) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # full without disaster indicator -->
<!-- # da_step_gam_table_empty_init_full <-  -->
<!-- #   step_gam('H2S_daily_avg', predictors_full, c(), 'stepwise', daily_full) -->
<!-- # da_step_gam_table_full_init_full <-  -->
<!-- #   step_gam('H2S_daily_avg', predictors_full, predictors_full, 'stepwise', daily_full) -->
<!-- ``` -->

<!-- Log Daily Average -->
<!-- ```{r} -->
<!-- # since feb 2022 stepwise -->
<!-- # log_da_step_gam_table_empty_init_sincefeb2022 <-  -->
<!-- #   step_gam('log(H2S_daily_avg)', predictors_sincefeb2022, c(), 'stepwise', data_sincefeb2022) -->
<!-- # log_da_step_gam_table_full_init_sincefeb2022 <-  -->
<!-- #   step_gam('log(H2S_daily_avg)', predictors_sincefeb2022, predictors_sincefeb2022, 'stepwise', data_sincefeb2022) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Disaster stepwise -->
<!-- # log_da_step_gam_table_empty_init_dis <-  -->
<!-- #   step_gam('log(H2S_daily_avg)', predictors_dis, c(), 'stepwise', data_dis) -->
<!-- # log_da_step_gam_table_full_init_dis <-  -->
<!-- #   step_gam('log(H2S_daily_avg)', predictors_dis, predictors_dis, 'stepwise', data_dis) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Exclude disaster stepwise -->
<!-- # log_da_step_gam_table_empty_init_excl_dis <-  -->
<!-- #   step_gam('log(H2S_daily_avg)', predictors_excl_dis, c(), 'stepwise', data_excl_dis) -->
<!-- # log_da_step_gam_table_full_init_excl_dis <-  -->
<!-- #   step_gam('log(H2S_daily_avg)', predictors_excl_dis, predictors_excl_dis, 'stepwise', data_excl_dis) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # full with disaster indicator -->
<!-- # log_da_step_gam_table_empty_init_dis_ind <-  -->
<!-- #   step_gam('log(H2S_daily_avg)', predictors_dis_ind, c(), 'stepwise', data_dis_ind) -->
<!-- # log_da_step_gam_table_full_init_dis_ind <-  -->
<!-- #   step_gam('log(H2S_daily_avg)', predictors_dis_ind, predictors_dis_ind, 'stepwise', data_dis_ind) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # full without disaster indicator -->
<!-- # log_da_step_gam_table_empty_init_full <-  -->
<!-- #   step_gam('log(H2S_daily_avg)', predictors_full, c(), 'stepwise', daily_full) -->
<!-- # log_da_step_gam_table_full_init_full <-  -->
<!-- #   step_gam('log(H2S_daily_avg)', predictors_full, predictors_full, 'stepwise', daily_full) -->
<!-- ``` -->

<!-- Daily Max -->
<!-- ```{r} -->
<!-- # since feb 2022 stepwise -->
<!-- # dm_step_gam_table_empty_init_sincefeb2022 <-  -->
<!-- #   step_gam('H2S_daily_max', predictors_sincefeb2022, c(), 'stepwise', data_sincefeb2022) -->
<!-- # dm_step_gam_table_full_init_sincefeb2022 <-  -->
<!-- #   step_gam('H2S_daily_max', predictors_sincefeb2022, predictors_sincefeb2022, 'stepwise', data_sincefeb2022) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Disaster stepwise -->
<!-- # dm_step_gam_table_empty_init_dis <-  -->
<!-- #   step_gam('H2S_daily_max', predictors_dis, c(), 'stepwise', data_dis) -->
<!-- # dm_step_gam_table_full_init_dis <-  -->
<!-- #   step_gam('H2S_daily_max', predictors_dis, predictors_dis, 'stepwise', data_dis) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Exclude disaster stepwise -->
<!-- # dm_step_gam_table_empty_init_excl_dis <-  -->
<!-- #   step_gam('H2S_daily_max', predictors_excl_dis, c(), 'stepwise', data_excl_dis) -->
<!-- # dm_step_gam_table_full_init_excl_dis <-  -->
<!-- #   step_gam('H2S_daily_max', predictors_excl_dis, predictors_excl_dis, 'stepwise', data_excl_dis) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # full with disaster indicator -->
<!-- # dm_step_gam_table_empty_init_dis_ind <-  -->
<!-- #   step_gam('H2S_daily_max', predictors_dis_ind, c(), 'stepwise', data_dis_ind) -->
<!-- # dm_step_gam_table_full_init_dis_ind <-  -->
<!-- #   step_gam('H2S_daily_max', predictors_dis_ind, predictors_dis_ind, 'stepwise', data_dis_ind) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # full without disaster indicator -->
<!-- # dm_step_gam_table_empty_init_full <-  -->
<!-- #   step_gam('H2S_daily_max', predictors_full, c(), 'stepwise', daily_full) -->
<!-- # dm_step_gam_table_full_init_full <-  -->
<!-- #   step_gam('H2S_daily_max', predictors_full, predictors_full, 'stepwise', daily_full) -->
<!-- ``` -->

<!-- Log Daily Max -->
<!-- ```{r} -->
<!-- # since feb 2022 stepwise -->
<!-- # log_dm_step_gam_table_empty_init_sincefeb2022 <-  -->
<!-- #   step_gam('log(H2S_daily_max)', predictors_sincefeb2022, c(), 'stepwise', data_sincefeb2022) -->
<!-- # log_dm_step_gam_table_full_init_sincefeb2022 <-  -->
<!-- #   step_gam('log(H2S_daily_max)', predictors_sincefeb2022, predictors_sincefeb2022, 'stepwise', data_sincefeb2022) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Disaster stepwise -->
<!-- # log_dm_step_gam_table_empty_init_dis <-  -->
<!-- #   step_gam('log(H2S_daily_max)', predictors_dis, c(), 'stepwise', data_dis) -->
<!-- # log_dm_step_gam_table_full_init_dis <-  -->
<!-- #   step_gam('log(H2S_daily_max)', predictors_dis, predictors_dis, 'stepwise', data_dis) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # Exclude disaster stepwise -->
<!-- # log_dm_step_gam_table_empty_init_excl_dis <-  -->
<!-- #   step_gam('log(H2S_daily_max)', predictors_excl_dis, c(), 'stepwise', data_excl_dis) -->
<!-- # log_dm_step_gam_table_full_init_excl_dis <-  -->
<!-- #   step_gam('log(H2S_daily_max)', predictors_excl_dis, predictors_excl_dis, 'stepwise', data_excl_dis) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # full with disaster indicator -->
<!-- # log_dm_step_gam_table_empty_init_dis_ind <-  -->
<!-- #   step_gam('log(H2S_daily_max)', predictors_dis_ind, c(), 'stepwise', data_dis_ind) -->
<!-- # log_dm_step_gam_table_full_init_dis_ind <-  -->
<!-- #   step_gam('log(H2S_daily_max)', predictors_dis_ind, predictors_dis_ind, 'stepwise', data_dis_ind) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- # full without disaster indicator -->
<!-- # log_dm_step_gam_table_empty_init_full <-  -->
<!-- #   step_gam('log(H2S_daily_max)', predictors_full, c(), 'stepwise', daily_full) -->
<!-- # log_dm_step_gam_table_full_init_full <-  -->
<!-- #   step_gam('log(H2S_daily_max)', predictors_full, predictors_full, 'stepwise', daily_full) -->
<!-- ``` -->

### Get best model size for each model
```{r}
# best_model_sizes <- smooth_models %>%
#   group_by(name, response, daterange) %>%
#   summarise(mean_smooth_res = mean(unlist(residuals)),
#             var_smooth_res = round(var(unlist(residuals))), 4) %>%
#   select(any_of(c('name', 'response', 'daterange', 
#                   'mean_smooth_res', 'var_smooth_res'))) %>%
#   mutate(Adj.R2 = NA,
#          best_R2 = NA,
#          CP = NA,
#          best_CP = NA,
#          BIC = NA,
#          best_BIC = NA,
#          linear_features = NA)
# for (i in 1:nrow(smooth_models)) {
#   regsubset <- summary(get(paste0(smooth_models$name[i], '_regsubsets')))
#   best_sizes <- tibble(Adj.R2 = which.max(regsubset$adjr2),
#                        best_R2 = regsubset$adjr2[which.max(regsubset$adjr2)],
#                        CP = which.min(regsubset$cp),
#                        best_CP = regsubset$cp[which.max(regsubset$cp)],
#                        BIC = which.min(regsubset$bic),
#                        best_BIC = regsubset$bic[which.max(regsubset$bic)],)
#   best_features <- tibble(linear_features = list(setdiff(names(regsubset$which[best_sizes$CP, ]
#                                                    [unlist(regsubset$which[best_sizes$CP, ])]), '(Intercept)')))
#   best_model_sizes[i,] <- bind_cols(best_model_sizes[i, 1:5], best_sizes, best_features)
# }
# 
# best_models <- best_model_sizes %>%
#   rowwise() %>%
#   mutate(smooth_features = if_else(daterange == 'dis', list(smooth_predictors[2:3]),
#                                    list(smooth_predictors))) %>%
#   mutate(full_features = list(c(unlist(smooth_features), unlist(linear_features)))) %>%
#   ungroup()
# 
# saveRDS(best_models, 'best_gam_models.rds')

best_gam_models <- readRDS('best_gam_models.rds')
```

### Save step tables
```{r}
# for (model_table_name in model_table_names) {
#   model_table <- get(model_table_name)
#   write_csv(model_table, paste0('step_gam_tables/', model_table_name, '.csv'))
# }
```

```{r}
# read model tables
# for (model_table_name in model_table_names) {
#   assign(model_table_name, 
#          read_csv(paste0('step_gam_tables/', model_table_name, '.csv')))
# }
```


```{r}
# model_features_table <- tibble(model_name = character(),
#                                GCV = numeric(),
#                                p = numeric(),
#                                features = list())
# 
# # for each model, find the best set of predictors
# for (model in model_table_names) {
#   step_gam_table <- get(model)
#   best_model <- step_gam_table[nrow(step_gam_table), ]
#   best_model_features <-names(best_model)[as.logical(c(0, unname(unlist(c(best_model[1,-1])))))]
#   model_features_table <- rbind(model_features_table, 
#                                 tibble(model_name = model,
#                                        GCV = best_model$GCV,
#                                        p = length(best_model_features),
#                                        features = list(best_model_features)))
# }
# 
# meta <- expand.grid(stat, init, date)
# names(meta) <- c('stat', 'init', 'date')
# model_features_table <- cbind(meta, model_features_table)
# 
# saveRDS(model_features_table, 'step_gam_tables/model_features_table.rds')
# model_features_table <- readRDS('step_gam_tables/model_features_table.rds')
```

## Final models

```{r}
# write function that takes in response, predictors, data and returns gam model 
# different from stepwise function, this has select = FALSE
get_feature_vector <- function(response, daterange) {
  feature_vec <-  best_gam_models %>%
      filter(response == .env$response & daterange == .env$daterange) %>%
      pull(full_features) %>%
      unlist()
  feature_vec <- str_replace_all(feature_vec, 'month\\d+', 'month')
  feature_vec <- str_replace_all(feature_vec, 'year\\d+', 'month')
  feature_vec <- str_replace_all(feature_vec, 'weekday\\D+', 'weekday')
  feature_vec <- unique(feature_vec)
  return(feature_vec)
}

get_data <- function(response, daterange) {
  if (response %in% hourly_responses &
      daterange == 'full') {
    data <- hourly_full
  } else if (response %in% hourly_responses){
    data <- get(paste0('hourly_data_', daterange))
  } else if (daterange == 'full') {
    data <- daily_full
  } else {
    data <- get(paste0('daily_data_', daterange))
  }
  return(data)
}

get_gam_model <- function(response, daterange) {
  predictors <- get_feature_vector(response, daterange)
  formula_feature_str <- paste(predictors, collapse = ' + ')
  formula_str <- paste(response, formula_feature_str, sep = ' ~ ')
  formula <- as.formula(formula_str)

  data <- get_data(response, daterange)
  gam_model <- gam(formula, data = data, method = 'GCV.Cp')
  return(gam_model)
}

# for (i in 1:nrow(best_gam_models)) {
#   model <- get_gam_model(best_gam_models$response[i],
#                          best_gam_models$daterange[i])
#   assign(paste0(best_gam_models$name[i], '_', best_gam_models$daterange[i], '_gam'), model)
#   saveRDS(model, paste0('gam_models/', paste0(best_gam_models$name[i], '_gam.rds')))
# }
```




```{r}
# # compare empty init vs full init and find best ones
# final_model_features_table <- model_features_table %>%
#   group_by(stat, date) %>%
#   filter(GCV == min(GCV))
# 
# final_model_features_table <- final_model_features_table %>%
#   select(-c(init, model_name)) %>%
#   distinct()
```

```{r}
for (i in 1:nrow(best_gam_models)) {
  assign(paste0(best_gam_models$name[i], '_gam'), 
         readRDS(paste0('gam_models/', best_gam_models$name[i], '_gam.rds')))
}
```


### Daily Average
Since February 2022
```{r}
# Since feb 2022
summary(da_sincefeb2022_gam)
```

Disaster Only
```{r}
# Disaster only
summary(da_dis_gam)
```

Exclude Disaster	
```{r}
# Exclude disaster
summary(da_excl_dis_gam)
```

Everything w Disaster Indicator	
```{r}
# Disaster indicator
summary(da_dis_ind_gam)
```

Everything w.o Disaster Indicator	
```{r}
# Everything
summary(da_full_gam)
```

### Log Daily Average
Since February 2022
```{r}
# Since feb 2022
summary(log_da_sincefeb2022_gam)
```

Disaster Only
```{r}
# Disaster only
summary(log_da_dis_gam)
```

Exclude Disaster	
```{r}
# Exclude disaster
summary(log_da_excl_dis_gam)
```

Everything w Disaster Indicator	
```{r}
# Disaster indicator
summary(log_da_dis_ind_gam)
```

Everything w.o Disaster Indicator	
```{r}
# Everything
summary(log_da_full_gam)
```

### Daily Max
Since February 2022
```{r}
# Since feb 2022
summary(dm_sincefeb2022_gam)
```

Disaster Only
```{r}
# Disaster only
summary(dm_dis_gam)
```

Exclude Disaster	
```{r}
# Exclude disaster
summary(dm_excl_dis_gam)
```

Everything w Disaster Indicator	
```{r}
# Disaster indicator
summary(dm_dis_ind_gam)
```

Everything w.o Disaster Indicator	
```{r}
# Everything
summary(dm_full_gam)
```

### Log Daily Max
Since February 2022
```{r}
# Since feb 2022
summary(log_dm_sincefeb2022_gam)
```

Disaster Only
```{r}
# Disaster only
summary(log_dm_dis_gam)
```

Exclude Disaster	
```{r}
# Exclude disaster
summary(log_dm_excl_dis_gam)
```

Everything w Disaster Indicator	
```{r}
# Disaster indicator
summary(log_dm_dis_ind_gam)
```

Everything w.o Disaster Indicator	
```{r}
# Everything
summary(log_dm_full_gam)
```

### Hourly Avg
Since February 2022
```{r}
# Since feb 2022
summary(ha_sincefeb2022_gam)
```

Disaster Only
```{r}
# Disaster only
summary(ha_dis_gam)
```

Exclude Disaster	
```{r}
# Exclude disaster
summary(ha_excl_dis_gam)
```

Everything w Disaster Indicator	
```{r}
# Disaster indicator
summary(ha_dis_ind_gam)
```

Everything w.o Disaster Indicator	
```{r}
# Everything
summary(ha_full_gam)
```

### Log Hourly Avg
Since February 2022
```{r}
# Since feb 2022
summary(log_ha_sincefeb2022_gam)
```

Disaster Only
```{r}
# Disaster only
summary(log_ha_dis_gam)
```

Exclude Disaster	
```{r}
# Exclude disaster
summary(log_ha_excl_dis_gam)
```

Everything w Disaster Indicator	
```{r}
# Disaster indicator
summary(log_ha_dis_ind_gam)
```

Everything w.o Disaster Indicator	
```{r}
# Everything
summary(log_ha_full_gam)
```

### Hourly Max
Since February 2022
```{r}
# Since feb 2022
summary(hm_sincefeb2022_gam)
```

Disaster Only
```{r}
# Disaster only
summary(hm_dis_gam)
```

Exclude Disaster	
```{r}
# Exclude disaster
summary(hm_excl_dis_gam)
```

Everything w Disaster Indicator	
```{r}
# Disaster indicator
summary(hm_dis_ind_gam)
```

Everything w.o Disaster Indicator	
```{r}
# Everything
summary(hm_full_gam)
```

### Log Hourly Max
Since February 2022
```{r}
# Since feb 2022
summary(log_hm_sincefeb2022_gam)
```

Disaster Only
```{r}
# Disaster only
summary(log_hm_dis_gam)
```

Exclude Disaster	
```{r}
# Exclude disaster
summary(log_hm_excl_dis_gam)
```

Everything w Disaster Indicator	
```{r}
# Disaster indicator
summary(log_hm_dis_ind_gam)
```

Everything w.o Disaster Indicator	
```{r}
# Everything
summary(log_hm_full_gam)
```

## Helper Function
```{r}
adj_r2 <- function(r2, n, p){
  # n-p since p here includes intercept
  return(1 - (1-r2)*(n - 1)/(n - p))
}

get_bt_adj_r2 <- function(name, response, daterange) {
  data <- get_data(response, daterange)
  model <- get(paste0(name,'_', daterange, '_gam'))
  response_colname <- names(model$model)[1]
  response_colname <- str_sub(response_colname, 5, -2)
  predictions <- predict(model, newdata = data) 
  bt_R2 <- R2(data %>% pull(response_colname), exp(predictions))
  bt_adj_r2 <- adj_r2(bt_R2, summary(model)$n, summary(model)$np)
  return(bt_adj_r2)
}
```

# GAM result
```{r}
# comp r2
data <- get_data('log(H2S_daily_avg)', 'dis_ind')
model <- get(paste0('log_da','_', 'dis_ind', '_gam'))
response_colname <- names(model$model)[1]
response_colname <- str_sub(response_colname, 5, -2)
predictions <- predict(model, newdata = data) 
bt_R2 <- R2(data %>% pull(response_colname), exp(predictions))

print('R2 computed using R2() function from caret package')
R2(data %>% pull(response_colname) %>% log(), predictions)
print('After adjusting for number of predictors')
adj_r2(R2(data %>% pull(response_colname) %>% log(), predictions),
       summary(model)$n, summary(model)$np)

print('BT-R2 computed using R2() function from caret package')
R2(data %>% pull(response_colname), exp(predictions))
print('After adjusting for number of predictors')
adj_r2(R2(data %>% pull(response_colname), exp(predictions)),
       summary(model)$n, summary(model)$np)

print('Returned by get_bt_adj_r2')
get_bt_adj_r2('log_da', 'log(H2S_daily_avg)', 'dis_ind')

print('Fit obs(y) ~ exp(predicted y)')
model_r2 <- lm(data %>% pull(response_colname) ~ exp(predictions))
summary(model_r2)$r.sq
summary(model_r2)$df[1] + summary(model_r2)$df[2]
summary(model_r2)$df[1]
summary(model_r2)$adj.r.squared
adj_r2(summary(model_r2)$r.sq,
       summary(model_r2)$df[1] + summary(model_r2)$df[2],
       summary(model_r2)$df[1])
```


```{r, fig.width=15}
date_names <- c('Since Feb 2022', 'Disaster Only', 'Exclude Disaster',
                'Everything w. Disaster Indicator', 
                'Everything w.o Disaster Indicator')
response_disp_names <- c('Daily Avg', 'Log Daily Avg', 'Daily Max', 'Log Daily Max',
                    'Hourly Avg', 'Log Hourly Avg', 'Hourly Max', 'Log Hourly Max')

gam_result_table <- expand.grid(date_names, response_disp_names) %>%
  setNames(c('date_names', 'response_disp_names'))

date_name_conversion <- tibble(date_names = date_names,
                               daterange = dateranges)

response_name_conversion <- tibble(response_disp_names = unique(gam_result_table$response_disp_names),
                                   response_obj_name = c(daily_responses, hourly_responses),
                                   model_response_name = response_names,
                                   transformation = rep(c('', 'Log'), 4))

gam_result_table <- gam_result_table %>%
  left_join(date_name_conversion) %>%
  left_join(response_name_conversion)

gam_result_table <- gam_result_table %>%
  mutate(adjr2 = NA, 
         bt_adjr2 = NA,
         n = NA,
         p = NA)

for (i in 1:nrow(gam_result_table)) {
  name <- gam_result_table$model_response_name[i]
  response <- gam_result_table$response_obj_name[i]
  daterange <- gam_result_table$daterange[i]
  model <- get(paste0(name,'_', daterange, '_gam'))
  if (str_detect(response, 'log\\(')) {
    bt_adjr2 <- get_bt_adj_r2(name, response, daterange)
  } else {
    bt_adjr2 <- NA
  }
  
  adjr2 <- summary(model)$r.sq
  n <- summary(model)$n
  p <- summary(model)$np
  
  new_columns <- tibble(adjr2 = adjr2, bt_adjr2 = bt_adjr2, n = n, p = p)
  new_row <- bind_cols(gam_result_table[i, 1:6], new_columns)
  gam_result_table[i, ] <- new_row
  print(str_glue('Completed {i} iterations'))
}

temp <- rep(rep(response_disp_names[!str_detect(response_disp_names, 'Log')], each =2), 5)

base_table <- gam_result_table %>%
  arrange(factor(date_names, levels = .env$date_names)) %>%
  mutate(response_base = temp,
       `bt_adjr2` = '') %>%
  filter(transformation == '') %>%
  select(all_of(c('date_names', 'response_base', 'model_response_name', 'adjr2', 'bt_adjr2', 'n', 'p'))) %>%
  select(-bt_adjr2)

log_table <- gam_result_table %>%
  arrange(factor(date_names, levels = .env$date_names)) %>%
  mutate(response_base = temp) %>%
  filter(transformation == 'Log') %>%
  select(all_of(c('date_names', 'response_base', 'model_response_name','adjr2', 'bt_adjr2', 'n', 'p')))

gam_result_table_fordisp <- base_table %>%
  left_join(log_table, join_by(date_names, response_base)) %>%
  select(-'date_names', -starts_with('model_response_name')) %>%
  setNames(c('Response', c('Adj.R2', 'N', 'P'), c('Adj.R2', 'BT-Adj.R2', 'N', 'P')))

gam_result_table_kable <- gam_result_table_fordisp %>%
  knitr::kable(format = 'latex', digits = 2) %>%
  pack_rows(index = c("Since Feb 2022" = 4, "Disaster Only" = 4, 
                      "Exclude Disaster" = 4, "Everything w D.I" = 4, "Everything w.o D.I" = 4)) %>%
  add_header_above(c(' ' = 1, 'No Transformation' = 3, 'Log-Transformation' = 4))

writeLines(gam_result_table_kable, '../figures/gam_result_table.tex')

gam_result_table_fordisp %>%
  knitr::kable(format = 'html', digits = 2, table.attr = "style='width:100%;'") %>%
  pack_rows(index = c("Since Feb 2022" = 4, "Disaster Only" = 4, 
                      "Exclude Disaster" = 4, "Everything w D.I" = 4, "Everything w.o D.I" = 4)) %>%
  add_header_above(c(' ' = 1, 'No Transformation' = 3, 'Log-Transformation' = 4))
```



# XGBoost (Daily Average)

## Since 2022 Feb
```{r echo = T, results = 'hide'}
validation_result <- tibble(Model = character(),
                               model_response_name = character(),
                               daterange = character(),
                               'Coef' = character(),
                               'R-Sq' = numeric(),
                               'Disaster RMSE' = numeric(),
                               'Normal RMSE' = numeric())

xgb_result <- tibble(Model = character(),
                        model_response_name = character(),
                        daterange = character(),
                        'Train R-Sq' = numeric(),
                        'Train BT R-Sq' = numeric(),
                        'Test R-Sq' = numeric(),
                        'Test BT R-Sq' = numeric(),
                        'Train RMSE' = numeric(),
                        'Train BT RMSE' = numeric(),
                        'Test RMSE' = numeric(),
                        'Test BT RMSE' = numeric())

fit.xgb_da_sincefeb2022 <- readRDS('../rfiles/xgboost_v2/fit.xgb_da_sincefeb2022.rds')
```

```{r}
getTrainPerf(fit.xgb_da_sincefeb2022)
```

```{r}
fit.xgb_da_sincefeb2022$finalModel
```

```{r}
names <- c("Longitude" = "mon_utm_x", 
           "Latitude" = "mon_utm_y",
           "Distance to Refinery" = "dist_ref", 
           "Angle to Refinery" = "angle_ref",
           "Active Wells within 2km" = "active_2km", 
           "Inactive Wells within 2km" = "inactive_2km",
           "Monthly Oil Production 2km" = "monthly_oil_2km",
           "Monthly Gas Production 2km" = "monthly_gas_2km",
           "Distance to WRP" = "dist_wrp",
           "WRP Capacity" = "closest_wrp_capacity",
           "Angle to WRP" = "angle_wrp",
           "Distance to Dominguez Channel" = "dist_dc",
           "Average Daily Temperature" = "daily_temp",
           "Average Daily Humidity" = "daily_hum",
           "Daily Precipitation" = "daily_precip",
           "Average Daily Wind Speed" = "ws_avg",
           "Average Daily Wind Direction" = "wd_avg",
           "Downwind Refinery" = "daily_downwind_ref",
           "Downwind WRP" = "daily_downwind_wrp",
           "Elevation" = "elevation",
           "Enhanced Vegetation Index" = "EVI",
           "Number of Daily Odor Complaints" = "num_odor_complaints",
           "2020" = "year_2020",
           "2021" = "year_2021",
           "2022" = "year_2022",
           "2023" = "year_2023",
           "January" = "month_01",
           "February" = "month_02",
           "March" = "month_03",
           "April" = "month_04",
           "May" = "month_05",
           "June" = "month_06", 
           "July" = "month_07",
           "August" = "month_08",
           "September" = "month_09",
           "October" = "month_10",
           "November" = "month_11",
           "December" = "month_12",
           "Monday" = "weekday_Mon",
           "Tuesday" = "weekday_Tue",
           "Wednesday" = "weekday_Wed",
           "Thursday" = "weekday_Thu",
           "Friday" = "weekday_Fri",
           "Saturday" = "weekday_Sat",
           "Sunday" = "weekday_Sun",
           "Disaster" = "disaster")

imp<-varImp(fit.xgb_da_sincefeb2022,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# we use savePredictions = 'final' to store the predictions on the test set at each fold

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_da_sincefeb2022$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_sincefeb2022_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_da_sincefeb2022$pred$obs, pred = fit.xgb_da_sincefeb2022$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for Since 2022 XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                              tibble(Model = 'Since Feb 2022',
                                     model_response_name = 'da',
                                     daterange = 'sincefeb2022',
                                     'Coef' = summary(lm(fit.xgb_da_sincefeb2022$pred$obs ~
                                                        fit.xgb_da_sincefeb2022$pred$pred))$coefficients[2, 1], 
                                     'R-Sq' = summary(lm(fit.xgb_da_sincefeb2022$pred$obs ~
                                                        fit.xgb_da_sincefeb2022$pred$pred))$r.squared,
                                     'Disaster RMSE' = NA,
                                     'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_da_sincefeb2022)$TrainRsquared,
                       nrow(fit.xgb_da_sincefeb2022$trainingData),
                       fit.xgb_da_sincefeb2022$finalModel$nfeatures)

test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_da_sincefeb2022$trainingData),
                       fit.xgb_da_sincefeb2022$finalModel$nfeatures)

xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Since Feb 2022',
                        model_response_name = 'da',
                        daterange = 'sincefeb2022',
                        'Train R-Sq' = train_adj_r2,
                        'Train BT R-Sq' = NA,
                        'Test R-Sq' = test_adj_r2,
                        'Test BT R-Sq' = NA,
                        'Train RMSE' = getTrainPerf(fit.xgb_da_sincefeb2022)$TrainRMSE,
                        'Train BT RMSE' = NA,
                        'Test RMSE' = test_rmse,
                        'Test BT RMSE' = NA))
```

## Disaster 

```{r echo = T, results = 'hide'}
fit.xgb_da_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_da_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_da_dis)
```

```{r}
fit.xgb_da_dis$finalModel
```


```{r}
imp<-varImp(fit.xgb_da_dis,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_r2 <- fold_stat <- fit.xgb_da_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_disaster_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_da_dis$pred$obs, pred = fit.xgb_da_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        # geom_abline(intercept = 0, slope = 1, color = 'red') +
                        # geom_smooth(method = 'lm', formula = y ~ x, geom = 'smooth') +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for Disaster Only XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_disaster_obs_vs_pred_plot_zoom <- ggplot(tibble(obs = fit.xgb_da_dis$pred$obs, pred = fit.xgb_da_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        geom_abline(intercept = 0, slope = 1, color = 'red') +
                        geom_smooth(method = 'lm', formula = y ~ x, geom = 'smooth') +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 50), ylim = c(0, 50)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Disaster Only',
                                  model_response_name = 'da',
                                  daterange = 'dis',
                                  'Coef' = summary(lm(fit.xgb_da_dis$pred$obs ~
                                                        fit.xgb_da_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_da_dis$pred$obs ~
                                                        fit.xgb_da_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_da_dis)$TrainRsquared,
                       nrow(fit.xgb_da_dis$trainingData),
                       fit.xgb_da_dis$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_da_dis$trainingData),
                       fit.xgb_da_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Disaster Only',
                              model_response_name = 'da',
                              daterange = 'dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_da_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```
## Exclude Disaster

```{r echo = T, results = 'hide'}
fit.xgb_da_excl_dis<- readRDS('../rfiles/xgboost_v2/fit.xgb_da_excl_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_da_excl_dis)
```

```{r}
fit.xgb_da_excl_dis$finalModel
```


```{r}
imp<-varImp(fit.xgb_da_excl_dis,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
fold_stat <- fit.xgb_da_excl_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_excl_dis_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_da_excl_dis$pred$obs, 
                                               pred = fit.xgb_da_excl_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for exclude disaster XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_excl_dis_obs_vs_pred_plot
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Exclude Disaster',
                                  model_response_name = 'da',
                                  daterange = 'excl_dis',
                                  'Coef' = summary(lm(fit.xgb_da_excl_dis$pred$obs ~
                                                        fit.xgb_da_excl_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_da_excl_dis$pred$obs ~
                                                        fit.xgb_da_excl_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_da_excl_dis)$TrainRsquared, 
                       nrow(fit.xgb_da_excl_dis$trainingData), 
                       fit.xgb_da_excl_dis$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2, 
                       nrow(fit.xgb_da_excl_dis$trainingData), 
                       fit.xgb_da_excl_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Exclude Disaster',
                              model_response_name = 'da',
                              daterange = 'excl_dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_da_excl_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```

## Everything w Disaster Indicator	

```{r echo = T, results = 'hide'}
fit.xgb_da_dis_ind <- readRDS('../rfiles/xgboost_v2/fit.xgb_da_dis_ind.rds')
```

```{r}
getTrainPerf(fit.xgb_da_dis_ind)
```

```{r}
fit.xgb_da_dis_ind$finalModel
```


```{r}
imp<-varImp(fit.xgb_da_dis_ind,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_da_dis_ind$pred$obs, 
                           pred = fit.xgb_da_dis_ind$pred$pred,
                           disaster = fit.xgb_da_dis_ind$trainingData$disaster[fit.xgb_da_dis_ind$pred$rowIndex])

fold_stat <- fit.xgb_da_dis_ind$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_dis_ind_obs_vs_pred_plot <- ggplot(tibble(obs = test_result_data$obs, 
                                                   pred = test_result_data$pred,
                                            disaster = test_result_data$disaster),
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for everything with disaster indicator XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_dis_ind_obs_vs_pred_plot_zoom <- ggplot(tibble(obs = test_result_data$obs, 
                                                   pred = test_result_data$pred,
                                            disaster = test_result_data$disaster),
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 30), ylim = c(0, 30)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Everything w. Disaster Indicator',
                                  model_response_name = 'da',
                                  daterange = 'dis_ind',
                                  'Coef' = summary(lm(fit.xgb_da_dis_ind$pred$obs ~
                                                        fit.xgb_da_dis_ind$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_da_dis_ind$pred$obs ~
                                                        fit.xgb_da_dis_ind$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                         test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_da_dis_ind)$TrainRsquared, 
                       nrow(fit.xgb_da_dis_ind$trainingData), 
                       fit.xgb_da_dis_ind$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2, 
                       nrow(fit.xgb_da_dis_ind$trainingData), 
                       fit.xgb_da_dis_ind$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Everything w. Disaster Indicator',
                              model_response_name = 'da',
                              daterange = 'dis_ind',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_da_dis_ind)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```
## Everything w.o Disaster Indicator	
```{r echo = T, results = 'hide'}
fit.xgb_da_full <- readRDS('../rfiles/xgboost_v2/fit.xgb_da_full.rds')
```

```{r}
getTrainPerf(fit.xgb_da_full)
```

```{r}
fit.xgb_da_full$finalModel
```


```{r}
imp<-varImp(fit.xgb_da_full,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_da_full$pred$obs, 
                           pred = fit.xgb_da_full$pred$pred,
                           disaster = if_else(fit.xgb_da_full$trainingData[fit.xgb_da_full$pred$rowIndex, ]$year_2021 == 1 &
                                                (fit.xgb_da_full$trainingData[fit.xgb_da_full$pred$rowIndex, ]$month_10 == 1 |
                                                 fit.xgb_da_full$trainingData[fit.xgb_da_full$pred$rowIndex, ]$month_11 == 1 |
                                                 fit.xgb_da_full$trainingData[fit.xgb_da_full$pred$rowIndex, ]$month_12 == 1), 1, 0))

fold_stat <- fit.xgb_da_full$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_everything_obs_vs_pred_plot <- ggplot(test_result_data,
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for everything XGBoost') +
                        theme_bw()

xgb_everything_obs_vs_pred_plot_zoom <- ggplot(test_result_data,
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 30), ylim = c(0, 30)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Everything w.o Disaster Indicator',
                                  model_response_name = 'da',
                                  daterange = 'full',
                                  'Coef' = summary(lm(test_result_data$obs ~
                                                        test_result_data$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(test_result_data$obs ~
                                                        test_result_data$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                         test_result_data$obs[which(test_result_data$disaster == 0)])))
```


```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_da_full)$TrainRsquared,
                       nrow(fit.xgb_da_full$trainingData),
                       fit.xgb_da_full$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_da_full$trainingData),
                       fit.xgb_da_full$finalModel$nfeatures)
xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Everything w.o Disaster Indicator',
                              model_response_name = 'da',
                              daterange = 'full',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_da_full)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```


## Observed Vs. Predicted Plots 10-fold CV
```{r}
ggarrange(xgb_sincefeb2022_obs_vs_pred_plot, 
          ggarrange(xgb_disaster_obs_vs_pred_plot, xgb_disaster_obs_vs_pred_plot_zoom,  
                    ncol = 2, labels = c("2", "3")),
          ggarrange(xgb_everything_obs_vs_pred_plot, xgb_everything_obs_vs_pred_plot_zoom, 
                    ncol = 2, labels = c("4", "5")), 
                    labels = c("1"),
                    nrow = 3)
ggarrange(xgb_excl_dis_obs_vs_pred_plot,
          ggarrange(xgb_dis_ind_obs_vs_pred_plot, xgb_dis_ind_obs_vs_pred_plot_zoom,  
                    ncol = 2, labels = c("3", "4")), 
                    labels = c("1"),
                    nrow = 2)
```

```{r}
knitr::kable(validation_result, digits = 3)
```


# XGBoost: log(H2S_daily_avg)
## Since Feb 2022
```{r}
fit.xgb_da_log_h2s_sincefeb2022 <- readRDS('../rfiles/xgboost_v2/fit.xgb_da_log_h2s_sincefeb2022.rds')
```

```{r}
getTrainPerf(fit.xgb_da_log_h2s_sincefeb2022)
```

```{r}
fit.xgb_da_log_h2s_sincefeb2022$finalModel
```

```{r}
imp<-varImp(fit.xgb_da_log_h2s_sincefeb2022,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_da_log_h2s_sincefeb2022$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_sincefeb2022_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_da_log_h2s_sincefeb2022$pred$obs), 
                                                              pred = exp(fit.xgb_da_log_h2s_sincefeb2022$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Since Februrary 2022') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.05) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.15) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Since Feb 2022',
                                  model_response_name = 'log_da',
                                  daterange = 'sincefeb2022',
                                  'Coef' = summary(lm(fit.xgb_da_log_h2s_sincefeb2022$pred$obs ~
                                                        fit.xgb_da_log_h2s_sincefeb2022$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_da_log_h2s_sincefeb2022$pred$obs ~
                                                        fit.xgb_da_log_h2s_sincefeb2022$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_da_log_h2s_sincefeb2022)$TrainRsquared, 
                       nrow(fit.xgb_da_log_h2s_sincefeb2022$trainingData), 
                       fit.xgb_da_log_h2s_sincefeb2022$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_da_log_h2s_sincefeb2022$trainingData), 
                       fit.xgb_da_log_h2s_sincefeb2022$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Since Feb 2022',
                              model_response_name = 'log_da',
                              daterange = 'sincefeb2022',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_r2_bt,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_da_log_h2s_sincefeb2022)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Disaster Only
```{r}
fit.xgb_da_log_h2s_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_da_log_h2s_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_da_log_h2s_dis)
```

```{r}
fit.xgb_da_log_h2s_dis$finalModel
```

```{r}
imp<-varImp(fit.xgb_da_log_h2s_dis,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_da_log_h2s_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_dis_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_da_log_h2s_dis$pred$obs), 
                                                              pred = exp(fit.xgb_da_log_h2s_dis$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Disaster Only') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.03) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.18) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Disaster Only',
                                  model_response_name = 'log_da',
                                  daterange = 'dis',
                                  'Coef' = summary(lm(fit.xgb_da_log_h2s_dis$pred$obs ~
                                                        fit.xgb_da_log_h2s_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_da_log_h2s_dis$pred$obs ~
                                                        fit.xgb_da_log_h2s_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_da_log_h2s_dis)$TrainRsquared, 
                       nrow(fit.xgb_da_log_h2s_dis$trainingData), 
                       fit.xgb_da_log_h2s_dis$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_da_log_h2s_dis$trainingData), 
                       fit.xgb_da_log_h2s_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Disaster Only',
                              model_response_name = 'log_da',
                              daterange = 'dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_da_log_h2s_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```


## Exclude Disaster
```{r}
fit.xgb_da_log_h2s_excl_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_da_log_h2s_excl_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_da_log_h2s_excl_dis)
```

```{r}
fit.xgb_da_log_h2s_excl_dis$finalModel
```

```{r}
imp<-varImp(fit.xgb_da_log_h2s_excl_dis,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_da_log_h2s_excl_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_excl_dis_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_da_log_h2s_excl_dis$pred$obs), 
                                                              pred = exp(fit.xgb_da_log_h2s_excl_dis$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Exclude Disaster') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.15) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.05) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Exclude Disaster',
                                  model_response_name = 'log_da',
                                  daterange = 'excl_dis',
                                  'Coef' = summary(lm(fit.xgb_da_log_h2s_excl_dis$pred$obs ~
                                                        fit.xgb_da_log_h2s_excl_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_da_log_h2s_excl_dis$pred$obs ~
                                                        fit.xgb_da_log_h2s_excl_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```


```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_da_log_h2s_excl_dis)$TrainRsquared, 
                       nrow(fit.xgb_da_log_h2s_excl_dis$trainingData), 
                       fit.xgb_da_log_h2s_excl_dis$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_da_log_h2s_excl_dis$trainingData), 
                       fit.xgb_da_log_h2s_excl_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Exclude Disaster',
                              model_response_name = 'log_da',
                              daterange = 'excl_dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_da_log_h2s_excl_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Everything w. Disaster Indicator
```{r}
fit.xgb_da_log_h2s_dis_ind <- readRDS('../rfiles/xgboost_v2/fit.xgb_da_log_h2s_dis_ind.rds')
```

```{r}
getTrainPerf(fit.xgb_da_log_h2s_dis_ind)
```

```{r}
fit.xgb_da_log_h2s_dis_ind$finalModel
```

```{r}
imp<-varImp(fit.xgb_da_log_h2s_dis_ind,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_da_log_h2s_dis_ind$pred$obs, 
                           pred = fit.xgb_da_log_h2s_dis_ind$pred$pred,
                           disaster = fit.xgb_da_log_h2s_dis_ind$trainingData$disaster[fit.xgb_da_log_h2s_dis_ind$pred$rowIndex])
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_da_log_h2s_dis_ind$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_dis_ind_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_da_log_h2s_dis_ind$pred$obs), 
                                                              pred = exp(fit.xgb_da_log_h2s_dis_ind$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Everything w. Disaster Indicator') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.03) + 
                        stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.08) + 
                        stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.17) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Everything w. Disaster Indicator',
                                  model_response_name = 'log_da',
                                  daterange = 'dis_ind',
                                  'Coef' = summary(lm(fit.xgb_da_log_h2s_dis_ind$pred$obs ~
                                                        fit.xgb_da_log_h2s_dis_ind$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_da_log_h2s_dis_ind$pred$obs ~
                                                        fit.xgb_da_log_h2s_dis_ind$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                       test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_da_log_h2s_dis_ind)$TrainRsquared, 
                       nrow(fit.xgb_da_log_h2s_dis_ind$trainingData), 
                       fit.xgb_da_log_h2s_dis_ind$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_da_log_h2s_dis_ind$trainingData), 
                       fit.xgb_da_log_h2s_dis_ind$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                    tibble(Model = 'Everything w. Disaster Indicator',
                              model_response_name = 'log_da',
                              daterange = 'dis_ind',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_da_log_h2s_dis_ind)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Everything w.o Disaster Indicator
```{r}
fit.xgb_da_log_h2s_full <- readRDS('../rfiles/xgboost_v2/fit.xgb_da_log_h2s_full.rds')
```

```{r}
getTrainPerf(fit.xgb_da_log_h2s_full)
```

```{r}
fit.xgb_da_log_h2s_full$finalModel
```

```{r}
imp<-varImp(fit.xgb_da_log_h2s_full,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_da_log_h2s_full$pred$obs, 
                           pred = fit.xgb_da_log_h2s_full$pred$pred,
                           disaster = if_else(fit.xgb_da_log_h2s_full$trainingData[fit.xgb_da_log_h2s_full$pred$rowIndex, ]$year_2021 == 1 &
                                                (fit.xgb_da_log_h2s_full$trainingData[fit.xgb_da_log_h2s_full$pred$rowIndex, ]$month_10 == 1 |
                                                 fit.xgb_da_log_h2s_full$trainingData[fit.xgb_da_log_h2s_full$pred$rowIndex, ]$month_11 == 1 |
                                                 fit.xgb_da_log_h2s_full$trainingData[fit.xgb_da_log_h2s_full$pred$rowIndex, ]$month_12 == 1), 1, 0))

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_da_log_h2s_full$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_full_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_da_log_h2s_full$pred$obs), 
                                                              pred = exp(fit.xgb_da_log_h2s_full$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Everything w.o Disaster Indicator') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.15) + 
                        stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 
                        stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.05) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Everything w.o Disaster Indicator',
                                  model_response_name = 'log_da',
                                  daterange = 'full',
                                  'Coef' = summary(lm(fit.xgb_da_log_h2s_full$pred$obs ~
                                                        fit.xgb_da_log_h2s_full$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_da_log_h2s_full$pred$obs ~
                                                        fit.xgb_da_log_h2s_full$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                       test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_da_log_h2s_full)$TrainRsquared, 
                       nrow(fit.xgb_da_log_h2s_full$trainingData), 
                       fit.xgb_da_log_h2s_full$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt, 
                       nrow(fit.xgb_da_log_h2s_full$trainingData), 
                       fit.xgb_da_log_h2s_full$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Everything w.o Disaster Indicator',
                              model_response_name = 'log_da',
                              daterange = 'full',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_da_log_h2s_full)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

# XGBoost (Daily Max)

## Since 2022 Feb
```{r echo = T, results = 'hide'}
fit.xgb_dm <- readRDS('../rfiles/xgboost_v2/fit.xgb_dm.rds')
```

```{r}
getTrainPerf(fit.xgb_dm)
```

```{r}
fit.xgb_dm$finalModel
```

```{r}
imp<-varImp(fit.xgb_dm,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# we use savePredictions = 'final' to store the predictions on the test set at each fold

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_dm$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_sincefeb2022_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_dm$pred$obs, pred = fit.xgb_dm$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for Since 2022 XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Since Feb 2022',
                                  model_response_name = 'dm',
                                  daterange = 'sincefeb2022',
                                  'Coef' = summary(lm(fit.xgb_dm$pred$obs ~
                                                        fit.xgb_dm$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_dm$pred$obs ~
                                                        fit.xgb_dm$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_dm)$TrainRsquared,
                       nrow(fit.xgb_dm$trainingData),
                       fit.xgb_dm$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_dm$trainingData),
                       fit.xgb_dm$finalModel$nfeatures)

xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Since Feb 2022',
                              model_response_name = 'dm',
                              daterange = 'sincefeb2022',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_dm)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```

## Disaster 

```{r echo = T, results = 'hide'}
fit.xgb_dm_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_dm_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_dm_dis)
```

```{r}
fit.xgb_dm_dis$finalModel
```


```{r}
imp<-varImp(fit.xgb_dm_dis,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_r2 <- fold_stat <- fit.xgb_dm_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_disaster_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_dm_dis$pred$obs, pred = fit.xgb_dm_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        # geom_abline(intercept = 0, slope = 1, color = 'red') +
                        # geom_smooth(method = 'lm', formula = y ~ x, geom = 'smooth') +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for Disaster Only XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_disaster_obs_vs_pred_plot_zoom <- ggplot(tibble(obs = fit.xgb_dm_dis$pred$obs, pred = fit.xgb_dm_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        geom_abline(intercept = 0, slope = 1, color = 'red') +
                        geom_smooth(method = 'lm', formula = y ~ x, geom = 'smooth') +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 50), ylim = c(0, 50)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Disaster Only',
                                  model_response_name = 'dm',
                                  daterange = 'dis',
                                  'Coef' = summary(lm(fit.xgb_dm_dis$pred$obs ~
                                                        fit.xgb_dm_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_dm_dis$pred$obs ~
                                                        fit.xgb_dm_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_dm_dis)$TrainRsquared,
                       nrow(fit.xgb_dm_dis$trainingData),
                       fit.xgb_dm_dis$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_dm_dis$trainingData),
                       fit.xgb_dm_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Disaster Only',
                              model_response_name = 'dm',
                              daterange = 'dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_dm_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```
## Exclude Disaster

```{r echo = T, results = 'hide'}
fit.xgb_dm_excl_dis<- readRDS('../rfiles/xgboost_v2/fit.xgb_dm_excl_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_dm_excl_dis)
```

```{r}
fit.xgb_dm_excl_dis$finalModel
```


```{r}
imp<-varImp(fit.xgb_dm_excl_dis,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
fold_stat <- fit.xgb_dm_excl_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_excl_dis_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_dm_excl_dis$pred$obs, 
                                               pred = fit.xgb_dm_excl_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for exclude disaster XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_excl_dis_obs_vs_pred_plot
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Exclude Disaster',
                                  model_response_name = 'dm',
                                  daterange = 'excl_dis',
                                  'Coef' = summary(lm(fit.xgb_dm_excl_dis$pred$obs ~
                                                        fit.xgb_dm_excl_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_dm_excl_dis$pred$obs ~
                                                        fit.xgb_dm_excl_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_dm_excl_dis)$TrainRsquared, 
                       nrow(fit.xgb_dm_excl_dis$trainingData), 
                       fit.xgb_dm_excl_dis$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2, 
                       nrow(fit.xgb_dm_excl_dis$trainingData), 
                       fit.xgb_dm_excl_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Exclude Disaster',
                              model_response_name = 'dm',
                              daterange = 'excl_dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_dm_excl_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```

## Everything w Disaster Indicator	

```{r echo = T, results = 'hide'}
fit.xgb_dm_dis_ind <- readRDS('../rfiles/xgboost_v2/fit.xgb_dm_dis_ind.rds')
```

```{r}
getTrainPerf(fit.xgb_dm_dis_ind)
```

```{r}
fit.xgb_dm_dis_ind$finalModel
```


```{r}
imp<-varImp(fit.xgb_dm_dis_ind,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_dm_dis_ind$pred$obs, 
                           pred = fit.xgb_dm_dis_ind$pred$pred,
                           disaster = fit.xgb_dm_dis_ind$trainingData$disaster[fit.xgb_dm_dis_ind$pred$rowIndex])

fold_stat <- fit.xgb_dm_dis_ind$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_dis_ind_obs_vs_pred_plot <- ggplot(tibble(obs = test_result_data$obs, 
                                                   pred = test_result_data$pred,
                                            disaster = test_result_data$disaster),
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for everything with disaster indicator XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_dis_ind_obs_vs_pred_plot_zoom <- ggplot(tibble(obs = test_result_data$obs, 
                                                   pred = test_result_data$pred,
                                            disaster = test_result_data$disaster),
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 30), ylim = c(0, 30)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Everything w. Disaster Indicator',
                                  model_response_name = 'dm',
                                  daterange = 'dis_ind',
                                  'Coef' = summary(lm(fit.xgb_dm_dis_ind$pred$obs ~
                                                        fit.xgb_dm_dis_ind$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_dm_dis_ind$pred$obs ~
                                                        fit.xgb_dm_dis_ind$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                         test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_dm_dis_ind)$TrainRsquared, 
                       nrow(fit.xgb_dm_dis_ind$trainingData), 
                       fit.xgb_dm_dis_ind$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2, 
                       nrow(fit.xgb_dm_dis_ind$trainingData), 
                       fit.xgb_dm_dis_ind$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Everything w. Disaster Indicator',
                              model_response_name = 'dm',
                              daterange = 'dis_ind',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_dm_dis_ind)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```
## Everything w.o Disaster Indicator	

```{r echo = T, results = 'hide'}
fit.xgb_dm_full <- readRDS('../rfiles/xgboost_v2/fit.xgb_dm_full.rds')
```

```{r}
getTrainPerf(fit.xgb_dm_full)
```

```{r}
fit.xgb_dm_full$finalModel
```


```{r}
imp<-varImp(fit.xgb_dm_full,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_dm_full$pred$obs, 
                           pred = fit.xgb_dm_full$pred$pred,
                           disaster = if_else(fit.xgb_dm_full$trainingData[fit.xgb_dm_full$pred$rowIndex, ]$year_2021 == 1 &
                                                (fit.xgb_dm_full$trainingData[fit.xgb_dm_full$pred$rowIndex, ]$month_10 == 1 |
                                                 fit.xgb_dm_full$trainingData[fit.xgb_dm_full$pred$rowIndex, ]$month_11 == 1 |
                                                 fit.xgb_dm_full$trainingData[fit.xgb_dm_full$pred$rowIndex, ]$month_12 == 1), 1, 0))

fold_stat <- fit.xgb_dm_full$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_everything_obs_vs_pred_plot <- ggplot(test_result_data,
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for everything XGBoost') +
                        theme_bw()

xgb_everything_obs_vs_pred_plot_zoom <- ggplot(test_result_data,
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 30), ylim = c(0, 30)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Everything w.o Disaster Indicator',
                                  model_response_name = 'dm',
                                  daterange = 'full',
                                  'Coef' = summary(lm(test_result_data$obs ~
                                                        test_result_data$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(test_result_data$obs ~
                                                        test_result_data$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                         test_result_data$obs[which(test_result_data$disaster == 0)])))
```


```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_dm_full)$TrainRsquared,
                       nrow(fit.xgb_dm_full$trainingData),
                       fit.xgb_dm_full$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_dm_full$trainingData),
                       fit.xgb_dm_full$finalModel$nfeatures)
xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Everything w.o Disaster Indicator',
                              model_response_name = 'dm',
                              daterange = 'full',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_dm_full)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```

# XGBoost: log(H2S_daily_max)
## Since Feb 2022
```{r}
fit.xgb_dm_log_h2s_sincefeb2022 <- readRDS('../rfiles/xgboost_v2/fit.xgb_dm_log_h2s_sincefeb2022.rds')
```

```{r}
getTrainPerf(fit.xgb_dm_log_h2s_sincefeb2022)
```

```{r}
fit.xgb_dm_log_h2s_sincefeb2022$finalModel
```

```{r}
imp<-varImp(fit.xgb_dm_log_h2s_sincefeb2022,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_dm_log_h2s_sincefeb2022$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_sincefeb2022_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_dm_log_h2s_sincefeb2022$pred$obs), 
                                                              pred = exp(fit.xgb_dm_log_h2s_sincefeb2022$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Since Februrary 2022') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.05) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.15) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Since Feb 2022',
                                  model_response_name = 'log_dm',
                                  daterange = 'sincefeb2022',
                                  'Coef' = summary(lm(fit.xgb_dm_log_h2s_sincefeb2022$pred$obs ~
                                                        fit.xgb_dm_log_h2s_sincefeb2022$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_dm_log_h2s_sincefeb2022$pred$obs ~
                                                        fit.xgb_dm_log_h2s_sincefeb2022$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_dm_log_h2s_sincefeb2022)$TrainRsquared, 
                       nrow(fit.xgb_dm_log_h2s_sincefeb2022$trainingData), 
                       fit.xgb_dm_log_h2s_sincefeb2022$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_dm_log_h2s_sincefeb2022$trainingData), 
                       fit.xgb_dm_log_h2s_sincefeb2022$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Since Feb 2022',
                              model_response_name = 'log_dm',
                              daterange = 'sincefeb2022',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_dm_log_h2s_sincefeb2022)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Disaster Only
```{r}
fit.xgb_dm_log_h2s_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_dm_log_h2s_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_dm_log_h2s_dis)
```

```{r}
fit.xgb_dm_log_h2s_dis$finalModel
```

```{r}
imp<-varImp(fit.xgb_dm_log_h2s_dis,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_dm_log_h2s_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_dis_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_dm_log_h2s_dis$pred$obs), 
                                                              pred = exp(fit.xgb_dm_log_h2s_dis$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Disaster Only') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.03) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.18) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Disaster Only',
                                  model_response_name = 'log_dm',
                                  daterange = 'dis',
                                  'Coef' = summary(lm(fit.xgb_dm_log_h2s_dis$pred$obs ~
                                                        fit.xgb_dm_log_h2s_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_dm_log_h2s_dis$pred$obs ~
                                                        fit.xgb_dm_log_h2s_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_dm_log_h2s_dis)$TrainRsquared, 
                       nrow(fit.xgb_dm_log_h2s_dis$trainingData), 
                       fit.xgb_dm_log_h2s_dis$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_dm_log_h2s_dis$trainingData), 
                       fit.xgb_dm_log_h2s_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Disaster Only',
                              model_response_name = 'log_dm',
                              daterange = 'dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_dm_log_h2s_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```


## Exclude Disaster
```{r}
fit.xgb_dm_log_h2s_excl_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_dm_log_h2s_excl_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_dm_log_h2s_excl_dis)
```

```{r}
fit.xgb_dm_log_h2s_excl_dis$finalModel
```

```{r}
imp<-varImp(fit.xgb_dm_log_h2s_excl_dis,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_dm_log_h2s_excl_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_excl_dis_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_dm_log_h2s_excl_dis$pred$obs), 
                                                              pred = exp(fit.xgb_dm_log_h2s_excl_dis$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Exclude Disaster') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.15) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.05) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Exclude Disaster',
                                  model_response_name = 'log_dm',
                                  daterange = 'excl_dis',
                                  'Coef' = summary(lm(fit.xgb_dm_log_h2s_excl_dis$pred$obs ~
                                                        fit.xgb_dm_log_h2s_excl_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_dm_log_h2s_excl_dis$pred$obs ~
                                                        fit.xgb_dm_log_h2s_excl_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```


```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_dm_log_h2s_excl_dis)$TrainRsquared, 
                       nrow(fit.xgb_dm_log_h2s_excl_dis$trainingData), 
                       fit.xgb_dm_log_h2s_excl_dis$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_dm_log_h2s_excl_dis$trainingData), 
                       fit.xgb_dm_log_h2s_excl_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Exclude Disaster',
                              model_response_name = 'log_dm',
                              daterange = 'excl_dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_dm_log_h2s_excl_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Everything w. Disaster Indicator
```{r}
fit.xgb_dm_log_h2s_dis_ind <- readRDS('../rfiles/xgboost_v2/fit.xgb_dm_log_h2s_dis_ind.rds')
```

```{r}
getTrainPerf(fit.xgb_dm_log_h2s_dis_ind)
```

```{r}
fit.xgb_dm_log_h2s_dis_ind$finalModel
```

```{r}
imp<-varImp(fit.xgb_dm_log_h2s_dis_ind,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_dm_log_h2s_dis_ind$pred$obs, 
                           pred = fit.xgb_dm_log_h2s_dis_ind$pred$pred,
                           disaster = fit.xgb_dm_log_h2s_dis_ind$trainingData$disaster[fit.xgb_dm_log_h2s_dis_ind$pred$rowIndex])

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_dm_log_h2s_dis_ind$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_dis_ind_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_dm_log_h2s_dis_ind$pred$obs), 
                                                              pred = exp(fit.xgb_dm_log_h2s_dis_ind$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Everything w. Disaster Indicator') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.03) + 
                        stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.08) + 
                        stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.17) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Everything w. Disaster Indicator',
                                  model_response_name = 'log_dm',
                                  daterange = 'dis_ind',
                                  'Coef' = summary(lm(fit.xgb_dm_log_h2s_dis_ind$pred$obs ~
                                                        fit.xgb_dm_log_h2s_dis_ind$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_dm_log_h2s_dis_ind$pred$obs ~
                                                        fit.xgb_dm_log_h2s_dis_ind$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                       test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_dm_log_h2s_dis_ind)$TrainRsquared, 
                       nrow(fit.xgb_dm_log_h2s_dis_ind$trainingData), 
                       fit.xgb_dm_log_h2s_dis_ind$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_dm_log_h2s_dis_ind$trainingData), 
                       fit.xgb_dm_log_h2s_dis_ind$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Everything w. Disaster Indicator',
                              model_response_name = 'log_dm',
                              daterange = 'dis_ind',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_dm_log_h2s_dis_ind)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Everything w.o Disaster Indicator
```{r}
fit.xgb_dm_log_h2s_full <- readRDS('../rfiles/xgboost_v2/fit.xgb_dm_log_h2s_full.rds')
```

```{r}
getTrainPerf(fit.xgb_dm_log_h2s_full)
```

```{r}
fit.xgb_dm_log_h2s_full$finalModel
```

```{r}
imp<-varImp(fit.xgb_dm_log_h2s_full,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```


```{r}
test_result_data <- tibble(obs = fit.xgb_dm_log_h2s_full$pred$obs, 
                           pred = fit.xgb_dm_log_h2s_full$pred$pred,
                           disaster = if_else(fit.xgb_dm_log_h2s_full$trainingData[fit.xgb_dm_log_h2s_full$pred$rowIndex, ]$year_2021 == 1 &
                                                (fit.xgb_dm_log_h2s_full$trainingData[fit.xgb_dm_log_h2s_full$pred$rowIndex, ]$month_10 == 1 |
                                                   fit.xgb_dm_log_h2s_full$trainingData[fit.xgb_dm_log_h2s_full$pred$rowIndex, ]$month_11 == 1 |
                                                   fit.xgb_dm_log_h2s_full$trainingData[fit.xgb_dm_log_h2s_full$pred$rowIndex, ]$month_12 == 1), 1, 0))

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_dm_log_h2s_full$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_full_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_dm_log_h2s_full$pred$obs), 
                                                              pred = exp(fit.xgb_dm_log_h2s_full$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Everything w.o Disaster Indicator') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.15) + 
                        stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 
                        stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.05) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Everything w.o Disaster Indicator',
                                  model_response_name = 'log_dm',
                                  daterange = 'full',
                                  'Coef' = summary(lm(fit.xgb_dm_log_h2s_full$pred$obs ~
                                                        fit.xgb_dm_log_h2s_full$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_dm_log_h2s_full$pred$obs ~
                                                        fit.xgb_dm_log_h2s_full$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                       test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_dm_log_h2s_full)$TrainRsquared, 
                       nrow(fit.xgb_dm_log_h2s_full$trainingData), 
                       fit.xgb_dm_log_h2s_full$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt, 
                       nrow(fit.xgb_dm_log_h2s_full$trainingData), 
                       fit.xgb_dm_log_h2s_full$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Everything w.o Disaster Indicator',
                              model_response_name = 'log_dm',
                              daterange = 'full',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_dm_log_h2s_full)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

# XGBoost (Hourly Average)

## Since 2022 Feb
```{r echo = T, results = 'hide'}
fit.xgb_ha_sincefeb2022 <- readRDS('../rfiles/xgboost_v2/fit.xgb_ha_sincefeb2022.rds')
```

```{r}
getTrainPerf(fit.xgb_ha_sincefeb2022)
```

```{r}
fit.xgb_ha_sincefeb2022$finalModel
```

```{r}
names <- c("Longitude" = "mon_utm_x", 
           "Latitude" = "mon_utm_y",
           "Distance to Refinery" = "dist_ref", 
           "Angle to Refinery" = "angle_ref",
           "Active Wells within 2km" = "active_2km", 
           "Inactive Wells within 2km" = "inactive_2km",
           "Monthly Oil Production 2km" = "monthly_oil_2km",
           "Monthly Gas Production 2km" = "monthly_gas_2km",
           "Distance to WRP" = "dist_wrp",
           "WRP Capacity" = "closest_wrp_capacity",
           "Angle to WRP" = "angle_wrp",
           "Distance to Dominguez Channel" = "dist_dc",
           "Hourly Temperature" = "hourly_temp",
           "Hourly Humidity" = "hourly_hum",
           "Hourly Precipitation" = "hourly_precip",
           "Hourly Wind Speed" = "ws_avg",
           "Hourly Wind Direction" = "wd_avg",
           "Downwind Refinery" = "hourly_downwind_ref",
           "Downwind WRP" = "hourly_downwind_wrp",
           "Elevation" = "elevation",
           "Enhanced Vegetation Index" = "EVI",
           "Number of Daily Odor Complaints" = "num_odor_complaints",
           "2020" = "year_2020",
           "2021" = "year_2021",
           "2022" = "year_2022",
           "2023" = "year_2023",
           "January" = "month_01",
           "February" = "month_02",
           "March" = "month_03",
           "April" = "month_04",
           "May" = "month_05",
           "June" = "month_06", 
           "July" = "month_07",
           "August" = "month_08",
           "September" = "month_09",
           "October" = "month_10",
           "November" = "month_11",
           "December" = "month_12",
           "Monday" = "weekday_Mon",
           "Tuesday" = "weekday_Tue",
           "Wednesday" = "weekday_Wed",
           "Thursday" = "weekday_Thu",
           "Friday" = "weekday_Fri",
           "Saturday" = "weekday_Sat",
           "Sunday" = "weekday_Sun",
           "Disaster" = "disaster")

imp<-varImp(fit.xgb_ha_sincefeb2022,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# we use savePredictions = 'final' to store the predictions on the test set at each fold

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_ha_sincefeb2022$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_sincefeb2022_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_ha_sincefeb2022$pred$obs, pred = fit.xgb_ha_sincefeb2022$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for Since 2022 XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                              tibble(Model = 'Since Feb 2022',
                                     model_response_name = 'ha',
                                     daterange = 'sincefeb2022',
                                     'Coef' = summary(lm(fit.xgb_ha_sincefeb2022$pred$obs ~
                                                        fit.xgb_ha_sincefeb2022$pred$pred))$coefficients[2, 1], 
                                     'R-Sq' = summary(lm(fit.xgb_ha_sincefeb2022$pred$obs ~
                                                        fit.xgb_ha_sincefeb2022$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_ha_sincefeb2022)$TrainRsquared,
                       nrow(fit.xgb_ha_sincefeb2022$trainingData),
                       fit.xgb_ha_sincefeb2022$finalModel$nfeatures)

test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_ha_sincefeb2022$trainingData),
                       fit.xgb_ha_sincefeb2022$finalModel$nfeatures)

xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Since Feb 2022',
                        model_response_name = 'ha',
                        daterange = 'sincefeb2022',
                        'Train R-Sq' = train_adj_r2,
                        'Train BT R-Sq' = NA,
                        'Test R-Sq' = test_adj_r2,
                        'Test BT R-Sq' = NA,
                        'Train RMSE' = getTrainPerf(fit.xgb_ha_sincefeb2022)$TrainRMSE,
                        'Train BT RMSE' = NA,
                        'Test RMSE' = test_rmse,
                        'Test BT RMSE' = NA))
```

## Disaster 

```{r echo = T, results = 'hide'}
fit.xgb_ha_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_ha_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_ha_dis)
```

```{r}
fit.xgb_ha_dis$finalModel
```


```{r}
imp<-varImp(fit.xgb_ha_dis,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_r2 <- fold_stat <- fit.xgb_ha_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_disaster_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_ha_dis$pred$obs, pred = fit.xgb_ha_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        # geom_abline(intercept = 0, slope = 1, color = 'red') +
                        # geom_smooth(method = 'lm', formula = y ~ x, geom = 'smooth') +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for Disaster Only XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_disaster_obs_vs_pred_plot_zoom <- ggplot(tibble(obs = fit.xgb_ha_dis$pred$obs, pred = fit.xgb_ha_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        geom_abline(intercept = 0, slope = 1, color = 'red') +
                        geom_smooth(method = 'lm', formula = y ~ x, geom = 'smooth') +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 50), ylim = c(0, 50)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Disaster Only',
                                  model_response_name = 'ha',
                                  daterange = 'dis',
                                  'Coef' = summary(lm(fit.xgb_ha_dis$pred$obs ~
                                                        fit.xgb_ha_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_ha_dis$pred$obs ~
                                                        fit.xgb_ha_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_ha_dis)$TrainRsquared,
                       nrow(fit.xgb_ha_dis$trainingData),
                       fit.xgb_ha_dis$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_ha_dis$trainingData),
                       fit.xgb_ha_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Disaster Only',
                              model_response_name = 'ha',
                              daterange = 'dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_ha_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```
## Exclude Disaster

```{r echo = T, results = 'hide'}
fit.xgb_ha_excl_dis<- readRDS('../rfiles/xgboost_v2/fit.xgb_ha_excl_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_ha_excl_dis)
```

```{r}
fit.xgb_ha_excl_dis$finalModel
```


```{r}
imp<-varImp(fit.xgb_ha_excl_dis,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
fold_stat <- fit.xgb_ha_excl_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_excl_dis_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_ha_excl_dis$pred$obs, 
                                               pred = fit.xgb_ha_excl_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for exclude disaster XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_excl_dis_obs_vs_pred_plot
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Exclude Disaster',
                                  model_response_name = 'ha',
                                  daterange = 'excl_dis',
                                  'Coef' = summary(lm(fit.xgb_ha_excl_dis$pred$obs ~
                                                        fit.xgb_ha_excl_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_ha_excl_dis$pred$obs ~
                                                        fit.xgb_ha_excl_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_ha_excl_dis)$TrainRsquared, 
                       nrow(fit.xgb_ha_excl_dis$trainingData), 
                       fit.xgb_ha_excl_dis$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2, 
                       nrow(fit.xgb_ha_excl_dis$trainingData), 
                       fit.xgb_ha_excl_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Exclude Disaster',
                              model_response_name = 'ha',
                              daterange = 'excl_dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_ha_excl_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```

## Everything w Disaster Indicator	

```{r echo = T, results = 'hide'}
fit.xgb_ha_dis_ind <- readRDS('../rfiles/xgboost_v2/fit.xgb_ha_dis_ind.rds')
```

```{r}
getTrainPerf(fit.xgb_ha_dis_ind)
```

```{r}
fit.xgb_ha_dis_ind$finalModel
```


```{r}
imp<-varImp(fit.xgb_ha_dis_ind,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_ha_dis_ind$pred$obs, 
                           pred = fit.xgb_ha_dis_ind$pred$pred,
                           disaster = fit.xgb_ha_dis_ind$trainingData$disaster[fit.xgb_ha_dis_ind$pred$rowIndex])

fold_stat <- fit.xgb_ha_dis_ind$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_dis_ind_obs_vs_pred_plot <- ggplot(tibble(obs = test_result_data$obs, 
                                                   pred = test_result_data$pred,
                                            disaster = test_result_data$disaster),
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for everything with disaster indicator XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_dis_ind_obs_vs_pred_plot_zoom <- ggplot(tibble(obs = test_result_data$obs, 
                                                   pred = test_result_data$pred,
                                            disaster = test_result_data$disaster),
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 30), ylim = c(0, 30)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Everything w. Disaster Indicator',
                                  model_response_name = 'ha',
                                  daterange = 'dis_ind',
                                  'Coef' = summary(lm(fit.xgb_ha_dis_ind$pred$obs ~
                                                        fit.xgb_ha_dis_ind$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_ha_dis_ind$pred$obs ~
                                                        fit.xgb_ha_dis_ind$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                         test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_ha_dis_ind)$TrainRsquared, 
                       nrow(fit.xgb_ha_dis_ind$trainingData), 
                       fit.xgb_ha_dis_ind$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2, 
                       nrow(fit.xgb_ha_dis_ind$trainingData), 
                       fit.xgb_ha_dis_ind$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Everything w. Disaster Indicator',
                              model_response_name = 'ha',
                              daterange = 'dis_ind',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_ha_dis_ind)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```
## Everything w.o Disaster Indicator	
```{r echo = T, results = 'hide'}
fit.xgb_ha_full <- readRDS('../rfiles/xgboost_v2/fit.xgb_ha_full.rds')
```

```{r}
getTrainPerf(fit.xgb_ha_full)
```

```{r}
fit.xgb_ha_full$finalModel
```


```{r}
imp<-varImp(fit.xgb_ha_full,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_ha_full$pred$obs, 
                           pred = fit.xgb_ha_full$pred$pred,
                           disaster = if_else(fit.xgb_ha_full$trainingData[fit.xgb_ha_full$pred$rowIndex, ]$year_2021 == 1 &
                                                (fit.xgb_ha_full$trainingData[fit.xgb_ha_full$pred$rowIndex, ]$month_10 == 1 |
                                                 fit.xgb_ha_full$trainingData[fit.xgb_ha_full$pred$rowIndex, ]$month_11 == 1 |
                                                 fit.xgb_ha_full$trainingData[fit.xgb_ha_full$pred$rowIndex, ]$month_12 == 1), 1, 0))

fold_stat <- fit.xgb_ha_full$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_everything_obs_vs_pred_plot <- ggplot(test_result_data,
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for everything XGBoost') +
                        theme_bw()

xgb_everything_obs_vs_pred_plot_zoom <- ggplot(test_result_data,
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 30), ylim = c(0, 30)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Everything w.o Disaster Indicator',
                                  model_response_name = 'ha',
                                  daterange = 'full',
                                  'Coef' = summary(lm(test_result_data$obs ~
                                                        test_result_data$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(test_result_data$obs ~
                                                        test_result_data$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                         test_result_data$obs[which(test_result_data$disaster == 0)])))
```


```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_ha_full)$TrainRsquared,
                       nrow(fit.xgb_ha_full$trainingData),
                       fit.xgb_ha_full$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_ha_full$trainingData),
                       fit.xgb_ha_full$finalModel$nfeatures)
xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Everything w.o Disaster Indicator',
                              model_response_name = 'ha',
                              daterange = 'full',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_ha_full)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```

# XGBoost: log(H2S_hourly_avg)
## Since Feb 2022
```{r}
fit.xgb_log_ha_sincefeb2022 <- readRDS('../rfiles/xgboost_v2/fit.xgb_log_ha_sincefeb2022.rds')
```

```{r}
getTrainPerf(fit.xgb_log_ha_sincefeb2022)
```

```{r}
fit.xgb_log_ha_sincefeb2022$finalModel
```

```{r}
imp<-varImp(fit.xgb_log_ha_sincefeb2022,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_log_ha_sincefeb2022$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_sincefeb2022_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_log_ha_sincefeb2022$pred$obs), 
                                                              pred = exp(fit.xgb_log_ha_sincefeb2022$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Since Februrary 2022') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.05) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.15) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Since Feb 2022',
                                  model_response_name = 'log_ha',
                                  daterange = 'sincefeb2022',
                                  'Coef' = summary(lm(fit.xgb_log_ha_sincefeb2022$pred$obs ~
                                                        fit.xgb_log_ha_sincefeb2022$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_log_ha_sincefeb2022$pred$obs ~
                                                        fit.xgb_log_ha_sincefeb2022$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_log_ha_sincefeb2022)$TrainRsquared, 
                       nrow(fit.xgb_log_ha_sincefeb2022$trainingData), 
                       fit.xgb_log_ha_sincefeb2022$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_log_ha_sincefeb2022$trainingData), 
                       fit.xgb_log_ha_sincefeb2022$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Since Feb 2022',
                              model_response_name = 'log_ha',
                              daterange = 'sincefeb2022',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_log_ha_sincefeb2022)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Disaster Only
```{r}
fit.xgb_log_ha_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_log_ha_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_log_ha_dis)
```

```{r}
fit.xgb_log_ha_dis$finalModel
```

```{r}
imp<-varImp(fit.xgb_log_ha_dis,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_log_ha_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_dis_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_log_ha_dis$pred$obs), 
                                                              pred = exp(fit.xgb_log_ha_dis$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Disaster Only') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.03) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.18) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Disaster Only',
                                  model_response_name = 'log_ha',
                                  daterange = 'dis',
                                  'Coef' = summary(lm(fit.xgb_log_ha_dis$pred$obs ~
                                                        fit.xgb_log_ha_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_log_ha_dis$pred$obs ~
                                                        fit.xgb_log_ha_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_log_ha_dis)$TrainRsquared, 
                       nrow(fit.xgb_log_ha_dis$trainingData), 
                       fit.xgb_log_ha_dis$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_log_ha_dis$trainingData), 
                       fit.xgb_log_ha_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Disaster Only',
                              model_response_name = 'log_ha',
                              daterange = 'dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_log_ha_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```


## Exclude Disaster
```{r}
fit.xgb_log_ha_excl_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_log_ha_excl_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_log_ha_excl_dis)
```

```{r}
fit.xgb_log_ha_excl_dis$finalModel
```

```{r}
imp<-varImp(fit.xgb_log_ha_excl_dis,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_log_ha_excl_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_excl_dis_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_log_ha_excl_dis$pred$obs), 
                                                              pred = exp(fit.xgb_log_ha_excl_dis$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Exclude Disaster') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.15) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.05) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Exclude Disaster',
                                  model_response_name = 'log_ha',
                                  daterange = 'excl_dis',
                                  'Coef' = summary(lm(fit.xgb_log_ha_excl_dis$pred$obs ~
                                                        fit.xgb_log_ha_excl_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_log_ha_excl_dis$pred$obs ~
                                                        fit.xgb_log_ha_excl_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```


```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_log_ha_excl_dis)$TrainRsquared, 
                       nrow(fit.xgb_log_ha_excl_dis$trainingData), 
                       fit.xgb_log_ha_excl_dis$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_log_ha_excl_dis$trainingData), 
                       fit.xgb_log_ha_excl_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Exclude Disaster',
                              model_response_name = 'log_ha',
                              daterange = 'excl_dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_log_ha_excl_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Everything w. Disaster Indicator
```{r}
fit.xgb_log_ha_dis_ind <- readRDS('../rfiles/xgboost_v2/fit.xgb_log_ha_dis_ind.rds')
```

```{r}
getTrainPerf(fit.xgb_log_ha_dis_ind)
```

```{r}
fit.xgb_log_ha_dis_ind$finalModel
```

```{r}
imp<-varImp(fit.xgb_log_ha_dis_ind,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_log_ha_dis_ind$pred$obs, 
                           pred = fit.xgb_log_ha_dis_ind$pred$pred,
                           disaster = fit.xgb_log_ha_dis_ind$trainingData$disaster[fit.xgb_log_ha_dis_ind$pred$rowIndex])

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_log_ha_dis_ind$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_dis_ind_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_log_ha_dis_ind$pred$obs), 
                                                              pred = exp(fit.xgb_log_ha_dis_ind$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Everything w. Disaster Indicator') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.03) + 
                        stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.08) + 
                        stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.17) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Everything w. Disaster Indicator',
                                  model_response_name = 'log_ha',
                                  daterange = 'dis_ind',
                                  'Coef' = summary(lm(fit.xgb_log_ha_dis_ind$pred$obs ~
                                                        fit.xgb_log_ha_dis_ind$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_log_ha_dis_ind$pred$obs ~
                                                        fit.xgb_log_ha_dis_ind$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                       test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_log_ha_dis_ind)$TrainRsquared, 
                       nrow(fit.xgb_log_ha_dis_ind$trainingData), 
                       fit.xgb_log_ha_dis_ind$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_log_ha_dis_ind$trainingData), 
                       fit.xgb_log_ha_dis_ind$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                    tibble(Model = 'Everything w. Disaster Indicator',
                              model_response_name = 'log_ha',
                              daterange = 'dis_ind',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_log_ha_dis_ind)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Everything w.o Disaster Indicator
```{r}
fit.xgb_log_ha_full <- readRDS('../rfiles/xgboost_v2/fit.xgb_log_ha_full.rds')
```

```{r}
getTrainPerf(fit.xgb_log_ha_full)
```

```{r}
fit.xgb_log_ha_full$finalModel
```

```{r}
imp<-varImp(fit.xgb_log_ha_full,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_log_ha_full$pred$obs, 
                           pred = fit.xgb_log_ha_full$pred$pred,
                           disaster = if_else(fit.xgb_log_ha_full$trainingData[fit.xgb_log_ha_full$pred$rowIndex, ]$year_2021 == 1 &
                                                (fit.xgb_log_ha_full$trainingData[fit.xgb_log_ha_full$pred$rowIndex, ]$month_10 == 1 |
                                                   fit.xgb_log_ha_full$trainingData[fit.xgb_log_ha_full$pred$rowIndex, ]$month_11 == 1 |
                                                   fit.xgb_log_ha_full$trainingData[fit.xgb_log_ha_full$pred$rowIndex, ]$month_12 == 1), 1, 0))

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_log_ha_full$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_full_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_log_ha_full$pred$obs), 
                                                              pred = exp(fit.xgb_log_ha_full$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Everything w.o Disaster Indicator') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.15) + 
                        stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 
                        stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.05) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Everything w.o Disaster Indicator',
                                  model_response_name = 'log_ha',
                                  daterange = 'full',
                                  'Coef' = summary(lm(fit.xgb_log_ha_full$pred$obs ~
                                                        fit.xgb_log_ha_full$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_log_ha_full$pred$obs ~
                                                        fit.xgb_log_ha_full$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                       test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_log_ha_full)$TrainRsquared, 
                       nrow(fit.xgb_log_ha_full$trainingData), 
                       fit.xgb_log_ha_full$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt, 
                       nrow(fit.xgb_log_ha_full$trainingData), 
                       fit.xgb_log_ha_full$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Everything w.o Disaster Indicator',
                              model_response_name = 'log_ha',
                              daterange = 'full',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_log_ha_full)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

# XGBoost (Hourly Max)

## Since 2022 Feb
```{r echo = T, results = 'hide'}
fit.xgb_hm_sincefeb2022 <- readRDS('../rfiles/xgboost_v2/fit.xgb_hm_sincefeb2022.rds')
```

```{r}
getTrainPerf(fit.xgb_hm_sincefeb2022)
```

```{r}
fit.xgb_hm_sincefeb2022$finalModel
```

```{r}
imp<-varImp(fit.xgb_hm_sincefeb2022,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# we use savePredictions = 'final' to store the predictions on the test set at each fold

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_hm_sincefeb2022$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_sincefeb2022_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_hm_sincefeb2022$pred$obs, pred = fit.xgb_hm_sincefeb2022$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for Since 2022 XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Since Feb 2022',
                                  model_response_name = 'hm',
                                  daterange = 'sincefeb2022',
                                  'Coef' = summary(lm(fit.xgb_hm_sincefeb2022$pred$obs ~
                                                        fit.xgb_hm_sincefeb2022$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_hm_sincefeb2022$pred$obs ~
                                                        fit.xgb_hm_sincefeb2022$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_hm_sincefeb2022)$TrainRsquared,
                       nrow(fit.xgb_hm_sincefeb2022$trainingData),
                       fit.xgb_hm_sincefeb2022$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_hm_sincefeb2022$trainingData),
                       fit.xgb_hm_sincefeb2022$finalModel$nfeatures)

xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Since Feb 2022',
                              model_response_name = 'hm',
                              daterange = 'sincefeb2022',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_hm_sincefeb2022)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```

## Disaster 

```{r echo = T, results = 'hide'}
fit.xgb_hm_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_hm_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_hm_dis)
```

```{r}
fit.xgb_hm_dis$finalModel
```


```{r}
imp<-varImp(fit.xgb_hm_dis,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_r2 <- fold_stat <- fit.xgb_hm_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_disaster_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_hm_dis$pred$obs, pred = fit.xgb_hm_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        # geom_abline(intercept = 0, slope = 1, color = 'red') +
                        # geom_smooth(method = 'lm', formula = y ~ x, geom = 'smooth') +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for Disaster Only XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_disaster_obs_vs_pred_plot_zoom <- ggplot(tibble(obs = fit.xgb_hm_dis$pred$obs, pred = fit.xgb_hm_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        geom_abline(intercept = 0, slope = 1, color = 'red') +
                        geom_smooth(method = 'lm', formula = y ~ x, geom = 'smooth') +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 50), ylim = c(0, 50)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Disaster Only',
                                  model_response_name = 'hm',
                                  daterange = 'dis',
                                  'Coef' = summary(lm(fit.xgb_hm_dis$pred$obs ~
                                                        fit.xgb_hm_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_hm_dis$pred$obs ~
                                                        fit.xgb_hm_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_hm_dis)$TrainRsquared,
                       nrow(fit.xgb_hm_dis$trainingData),
                       fit.xgb_hm_dis$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_hm_dis$trainingData),
                       fit.xgb_hm_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Disaster Only',
                              model_response_name = 'hm',
                              daterange = 'dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_hm_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```
## Exclude Disaster

```{r echo = T, results = 'hide'}
fit.xgb_hm_excl_dis<- readRDS('../rfiles/xgboost_v2/fit.xgb_hm_excl_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_hm_excl_dis)
```

```{r}
fit.xgb_hm_excl_dis$finalModel
```


```{r}
imp<-varImp(fit.xgb_hm_excl_dis,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
fold_stat <- fit.xgb_hm_excl_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_excl_dis_obs_vs_pred_plot <- ggplot(tibble(obs = fit.xgb_hm_excl_dis$pred$obs, 
                                               pred = fit.xgb_hm_excl_dis$pred$pred),
                             aes(x = pred, y = obs)) +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for exclude disaster XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_excl_dis_obs_vs_pred_plot
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Exclude Disaster',
                                  model_response_name = 'hm',
                                  daterange = 'excl_dis',
                                  'Coef' = summary(lm(fit.xgb_hm_excl_dis$pred$obs ~
                                                        fit.xgb_hm_excl_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_hm_excl_dis$pred$obs ~
                                                        fit.xgb_hm_excl_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_hm_excl_dis)$TrainRsquared, 
                       nrow(fit.xgb_hm_excl_dis$trainingData), 
                       fit.xgb_hm_excl_dis$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2, 
                       nrow(fit.xgb_hm_excl_dis$trainingData), 
                       fit.xgb_hm_excl_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Exclude Disaster',
                              model_response_name = 'hm',
                              daterange = 'excl_dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_hm_excl_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```

## Everything w Disaster Indicator	

```{r echo = T, results = 'hide'}
fit.xgb_hm_dis_ind <- readRDS('../rfiles/xgboost_v2/fit.xgb_hm_dis_ind.rds')
```

```{r}
getTrainPerf(fit.xgb_hm_dis_ind)
```

```{r}
fit.xgb_hm_dis_ind$finalModel
```


```{r}
imp<-varImp(fit.xgb_hm_dis_ind,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_hm_dis_ind$pred$obs, 
                           pred = fit.xgb_hm_dis_ind$pred$pred,
                           disaster = fit.xgb_hm_dis_ind$trainingData$disaster[fit.xgb_hm_dis_ind$pred$rowIndex])

fold_stat <- fit.xgb_hm_dis_ind$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_dis_ind_obs_vs_pred_plot <- ggplot(tibble(obs = test_result_data$obs, 
                                                   pred = test_result_data$pred,
                                            disaster = test_result_data$disaster),
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for everything with disaster indicator XGBoost') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        theme_bw()

xgb_dis_ind_obs_vs_pred_plot_zoom <- ggplot(tibble(obs = test_result_data$obs, 
                                                   pred = test_result_data$pred,
                                            disaster = test_result_data$disaster),
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 30), ylim = c(0, 30)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Everything w. Disaster Indicator',
                                  model_response_name = 'hm',
                                  daterange = 'dis_ind',
                                  'Coef' = summary(lm(fit.xgb_hm_dis_ind$pred$obs ~
                                                        fit.xgb_hm_dis_ind$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_hm_dis_ind$pred$obs ~
                                                        fit.xgb_hm_dis_ind$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                         test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_hm_dis_ind)$TrainRsquared, 
                       nrow(fit.xgb_hm_dis_ind$trainingData), 
                       fit.xgb_hm_dis_ind$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2, 
                       nrow(fit.xgb_hm_dis_ind$trainingData), 
                       fit.xgb_hm_dis_ind$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Everything w. Disaster Indicator',
                              model_response_name = 'hm',
                              daterange = 'dis_ind',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_hm_dis_ind)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```
## Everything w.o Disaster Indicator	

```{r echo = T, results = 'hide'}
fit.xgb_hm_full <- readRDS('../rfiles/xgboost_v2/fit.xgb_hm_full.rds')
```

```{r}
getTrainPerf(fit.xgb_hm_full)
```

```{r}
fit.xgb_hm_full$finalModel
```


```{r}
imp<-varImp(fit.xgb_hm_full,scale=FALSE)
# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_hm_full$pred$obs, 
                           pred = fit.xgb_hm_full$pred$pred,
                           disaster = if_else(fit.xgb_hm_full$trainingData[fit.xgb_hm_full$pred$rowIndex, ]$year_2021 == 1 &
                                                (fit.xgb_hm_full$trainingData[fit.xgb_hm_full$pred$rowIndex, ]$month_10 == 1 |
                                                 fit.xgb_hm_full$trainingData[fit.xgb_hm_full$pred$rowIndex, ]$month_11 == 1 |
                                                 fit.xgb_hm_full$trainingData[fit.xgb_hm_full$pred$rowIndex, ]$month_12 == 1), 1, 0))

fold_stat <- fit.xgb_hm_full$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs))
test_r2 <- mean(fold_stat$R2)
test_rmse <- mean(fold_stat$RMSE)
```

```{r}
xgb_everything_obs_vs_pred_plot <- ggplot(test_result_data,
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Observed vs Predicted for everything XGBoost') +
                        theme_bw()

xgb_everything_obs_vs_pred_plot_zoom <- ggplot(test_result_data,
                             aes(x = pred, y = obs)) +
                        geom_point(aes(col = factor(disaster)), show.legend = FALSE) +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq", "R2", "n"))) +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Zoomed In') +
                        coord_cartesian(xlim = c(0, 30), ylim = c(0, 30)) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result,  
                           tibble(Model = 'Everything w.o Disaster Indicator',
                                  model_response_name = 'hm',
                                  daterange = 'full',
                                  'Coef' = summary(lm(test_result_data$obs ~
                                                        test_result_data$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(test_result_data$obs ~
                                                        test_result_data$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                         test_result_data$obs[which(test_result_data$disaster == 0)])))
```


```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_hm_full)$TrainRsquared,
                       nrow(fit.xgb_hm_full$trainingData),
                       fit.xgb_hm_full$finalModel$nfeatures)
test_adj_r2 <- adj_r2(test_r2,
                       nrow(fit.xgb_hm_full$trainingData),
                       fit.xgb_hm_full$finalModel$nfeatures)
xgb_result <- rbind(xgb_result,
                       tibble(Model = 'Everything w.o Disaster Indicator',
                              model_response_name = 'hm',
                              daterange = 'full',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = NA,
                              'Train RMSE' = getTrainPerf(fit.xgb_hm_full)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = NA))
```

# XGBoost: log(H2S_hourly_max)
## Since Feb 2022
```{r}
fit.xgb_log_hm_sincefeb2022 <- readRDS('../rfiles/xgboost_v2/fit.xgb_log_hm_sincefeb2022.rds')
```

```{r}
getTrainPerf(fit.xgb_log_hm_sincefeb2022)
```

```{r}
fit.xgb_log_hm_sincefeb2022$finalModel
```

```{r}
imp<-varImp(fit.xgb_log_hm_sincefeb2022,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_log_hm_sincefeb2022$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_sincefeb2022_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_log_hm_sincefeb2022$pred$obs), 
                                                              pred = exp(fit.xgb_log_hm_sincefeb2022$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Since Februrary 2022') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.05) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.15) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Since Feb 2022',
                                  model_response_name = 'log_hm',
                                  daterange = 'sincefeb2022',
                                  'Coef' = summary(lm(fit.xgb_log_hm_sincefeb2022$pred$obs ~
                                                        fit.xgb_log_hm_sincefeb2022$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_log_hm_sincefeb2022$pred$obs ~
                                                        fit.xgb_log_hm_sincefeb2022$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_log_hm_sincefeb2022)$TrainRsquared, 
                       nrow(fit.xgb_log_hm_sincefeb2022$trainingData), 
                       fit.xgb_log_hm_sincefeb2022$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_log_hm_sincefeb2022$trainingData), 
                       fit.xgb_log_hm_sincefeb2022$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Since Feb 2022',
                              model_response_name = 'log_hm',
                              daterange = 'sincefeb2022',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_log_hm_sincefeb2022)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Disaster Only
```{r}
fit.xgb_log_hm_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_log_hm_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_log_hm_dis)
```

```{r}
fit.xgb_log_hm_dis$finalModel
```

```{r}
imp<-varImp(fit.xgb_log_hm_dis,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_log_hm_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_dis_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_log_hm_dis$pred$obs), 
                                                              pred = exp(fit.xgb_log_hm_dis$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Disaster Only') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.03) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.18) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Disaster Only',
                                  model_response_name = 'log_hm',
                                  daterange = 'dis',
                                  'Coef' = summary(lm(fit.xgb_log_hm_dis$pred$obs ~
                                                        fit.xgb_log_hm_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_log_hm_dis$pred$obs ~
                                                        fit.xgb_log_hm_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_log_hm_dis)$TrainRsquared, 
                       nrow(fit.xgb_log_hm_dis$trainingData), 
                       fit.xgb_log_hm_dis$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_log_hm_dis$trainingData), 
                       fit.xgb_log_hm_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Disaster Only',
                              model_response_name = 'log_hm',
                              daterange = 'dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_log_hm_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```


## Exclude Disaster
```{r}
fit.xgb_log_hm_excl_dis <- readRDS('../rfiles/xgboost_v2/fit.xgb_log_hm_excl_dis.rds')
```

```{r}
getTrainPerf(fit.xgb_log_hm_excl_dis)
```

```{r}
fit.xgb_log_hm_excl_dis$finalModel
```

```{r}
imp<-varImp(fit.xgb_log_hm_excl_dis,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_log_hm_excl_dis$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_excl_dis_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_log_hm_excl_dis$pred$obs), 
                                                              pred = exp(fit.xgb_log_hm_excl_dis$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Exclude Disaster') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.15) +                                                stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.05) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Exclude Disaster',
                                  model_response_name = 'log_hm',
                                  daterange = 'excl_dis',
                                  'Coef' = summary(lm(fit.xgb_log_hm_excl_dis$pred$obs ~
                                                        fit.xgb_log_hm_excl_dis$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_log_hm_excl_dis$pred$obs ~
                                                        fit.xgb_log_hm_excl_dis$pred$pred))$r.squared,
                                  'Disaster RMSE' = NA,
                                  'Normal RMSE' = NA))
```


```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_log_hm_excl_dis)$TrainRsquared, 
                       nrow(fit.xgb_log_hm_excl_dis$trainingData), 
                       fit.xgb_log_hm_excl_dis$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_log_hm_excl_dis$trainingData), 
                       fit.xgb_log_hm_excl_dis$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Exclude Disaster',
                              model_response_name = 'log_hm',
                              daterange = 'excl_dis',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_log_hm_excl_dis)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Everything w. Disaster Indicator
```{r}
fit.xgb_log_hm_dis_ind <- readRDS('../rfiles/xgboost_v2/fit.xgb_log_hm_dis_ind.rds')
```

```{r}
getTrainPerf(fit.xgb_log_hm_dis_ind)
```

```{r}
fit.xgb_log_hm_dis_ind$finalModel
```

```{r}
imp<-varImp(fit.xgb_log_hm_dis_ind,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_log_hm_dis_ind$pred$obs, 
                           pred = fit.xgb_log_hm_dis_ind$pred$pred,
                           disaster = fit.xgb_log_hm_dis_ind$trainingData$disaster[fit.xgb_log_hm_dis_ind$pred$rowIndex])

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_log_hm_dis_ind$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_dis_ind_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_log_hm_dis_ind$pred$obs), 
                                                              pred = exp(fit.xgb_log_hm_dis_ind$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Everything w. Disaster Indicator') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.03) + 
                        stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.08) + 
                        stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.17) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Everything w. Disaster Indicator',
                                  model_response_name = 'log_hm',
                                  daterange = 'dis_ind',
                                  'Coef' = summary(lm(fit.xgb_log_hm_dis_ind$pred$obs ~
                                                        fit.xgb_log_hm_dis_ind$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_log_hm_dis_ind$pred$obs ~
                                                        fit.xgb_log_hm_dis_ind$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                       test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_log_hm_dis_ind)$TrainRsquared, 
                       nrow(fit.xgb_log_hm_dis_ind$trainingData), 
                       fit.xgb_log_hm_dis_ind$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt,
                       nrow(fit.xgb_log_hm_dis_ind$trainingData), 
                       fit.xgb_log_hm_dis_ind$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Everything w. Disaster Indicator',
                              model_response_name = 'log_hm',
                              daterange = 'dis_ind',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_log_hm_dis_ind)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

## Everything w.o Disaster Indicator
```{r}
fit.xgb_log_hm_full <- readRDS('../rfiles/xgboost_v2/fit.xgb_log_hm_full.rds')
```

```{r}
getTrainPerf(fit.xgb_log_hm_full)
```

```{r}
fit.xgb_log_hm_full$finalModel
```

```{r}
imp<-varImp(fit.xgb_log_hm_full,scale=FALSE)

# rename variables
imp <- tibble(variable = rownames(imp$importance), importance = imp$importance$Overall) %>%
    pivot_wider(names_from = variable, 
                values_from = importance) %>%
    rename(any_of(names)) %>%
    pivot_longer(cols = everything(),names_to = 'variable', values_to = 'importance')

imp %>%
  top_n(15, importance) %>%
  ggplot(aes(x=reorder(variable, importance), y=importance)) + 
  geom_point() +
  geom_segment(aes(x=variable,xend=variable,y=0,yend=importance)) +
  ylab("importance") +
  xlab("Variable") +
  coord_flip() +
  theme_minimal()
```

```{r}
test_result_data <- tibble(obs = fit.xgb_log_hm_full$pred$obs, 
                           pred = fit.xgb_log_hm_full$pred$pred,
                           disaster = if_else(fit.xgb_log_hm_full$trainingData[fit.xgb_log_hm_full$pred$rowIndex, ]$year_2021 == 1 &
                                                (fit.xgb_log_hm_full$trainingData[fit.xgb_log_hm_full$pred$rowIndex, ]$month_10 == 1 |
                                                   fit.xgb_log_hm_full$trainingData[fit.xgb_log_hm_full$pred$rowIndex, ]$month_11 == 1 |
                                                   fit.xgb_log_hm_full$trainingData[fit.xgb_log_hm_full$pred$rowIndex, ]$month_12 == 1), 1, 0))

# Here, we compute the R2 and RMSE for each fold and take the average
fold_stat <- fit.xgb_log_hm_full$pred %>% group_by(Resample) %>% 
  summarise(R2 = R2(pred, obs), RMSE = RMSE(pred, obs),
            R2_BT = R2(exp(pred), exp(obs)), RMSE_BT = RMSE(exp(pred), exp(obs)))
test_r2 <- mean(fold_stat$R2)
test_r2_bt <- mean(fold_stat$R2_BT)
test_rmse <- mean(fold_stat$RMSE)
test_rmse_bt <- mean(fold_stat$RMSE_BT)
```

```{r}
log_h2s_xgb_full_obs_vs_pred_plot <- ggplot(tibble(obs = exp(fit.xgb_log_hm_full$pred$obs), 
                                                              pred = exp(fit.xgb_log_hm_full$pred$pred)),
                             aes(x = pred, y = obs)) +
                        geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +                                                         
                        geom_point() +
                        labs(y = 'Observed', x = 'Predicted', 
                             title = 'Everything w.o Disaster Indicator') +
                        stat_poly_line() +
                        stat_poly_eq(use_label(c("eq")), label.x = "right", label.y = 0.15) + 
                        stat_poly_eq(use_label(c("R2")), label.x = "right", label.y = 0.1) +                                                 
                        stat_poly_eq(use_label(c("n")), label.x = "right", label.y = 0.05) +
                        theme_bw()
```

```{r}
validation_result <- rbind(validation_result, 
                           tibble(Model = 'Everything w.o Disaster Indicator',
                                  model_response_name = 'log_hm',
                                  daterange = 'full',
                                  'Coef' = summary(lm(fit.xgb_log_hm_full$pred$obs ~
                                                        fit.xgb_log_hm_full$pred$pred))$coefficients[2, 1], 
                                  'R-Sq' = summary(lm(fit.xgb_log_hm_full$pred$obs ~
                                                        fit.xgb_log_hm_full$pred$pred))$r.squared,
                                  'Disaster RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 1)],
                                                         test_result_data$obs[which(test_result_data$disaster == 1)]),
                                  'Normal RMSE' = RMSE(test_result_data$pred[which(test_result_data$disaster == 0)],
                                                       test_result_data$obs[which(test_result_data$disaster == 0)])))
```

```{r}
train_adj_r2 <- adj_r2(getTrainPerf(fit.xgb_log_hm_full)$TrainRsquared, 
                       nrow(fit.xgb_log_hm_full$trainingData), 
                       fit.xgb_log_hm_full$finalModel$nfeatures)
BT_adj_r2 <- adj_r2(test_r2_bt, 
                       nrow(fit.xgb_log_hm_full$trainingData), 
                       fit.xgb_log_hm_full$finalModel$nfeatures)

xgb_result <- rbind(xgb_result, 
                       tibble(Model = 'Everything w.o Disaster Indicator',
                              model_response_name = 'log_hm',
                              daterange = 'full',
                              'Train R-Sq' = train_adj_r2,
                              'Train BT R-Sq' = NA,
                              'Test R-Sq' = test_adj_r2,
                              'Test BT R-Sq' = BT_adj_r2,
                              'Train RMSE' = getTrainPerf(fit.xgb_log_hm_full)$TrainRMSE,
                              'Train BT RMSE' = NA,
                              'Test RMSE' = test_rmse,
                              'Test BT RMSE' = test_rmse_bt))
```

# XGB Model performances
```{r}
validation_result
```

```{r}
xgb_result
```

# GAM VS XGBoost
```{r}
base_validation_result <- validation_result %>%
  mutate(transformation = if_else(str_detect(model_response_name, 'log_'), 'Log', '')) %>%
  filter(transformation == '')

log_validation_result <- validation_result %>%
  mutate(transformation = if_else(str_detect(model_response_name, 'log_'), 'Log', '')) %>%
  filter(transformation == 'Log')

base_xgb_result <- xgb_result %>%
  mutate(transformation = if_else(str_detect(model_response_name, 'log_'), 'Log', '')) %>%
  filter(transformation == '') %>%
  mutate(response_base = case_when(str_detect(model_response_name, 'da') ~ 'Daily Avg',
                                   str_detect(model_response_name, 'dm') ~ 'Daily Max',
                                   str_detect(model_response_name, 'ha') ~ 'Hourly Avg',
                                   str_detect(model_response_name, 'hm') ~ 'Hourly Max')) %>%
  select(-transformation, -`Train BT R-Sq`, -`Train BT RMSE`, -`Test BT R-Sq`, -`Test BT RMSE`)

log_xgb_result <- xgb_result %>%
  mutate(transformation = if_else(str_detect(model_response_name, 'log_'), 'Log', '')) %>%
  filter(transformation == 'Log') %>%
  mutate(response_base = case_when(str_detect(model_response_name, 'da') ~ 'Daily Avg',
                                   str_detect(model_response_name, 'dm') ~ 'Daily Max',
                                   str_detect(model_response_name, 'ha') ~ 'Hourly Avg',
                                   str_detect(model_response_name, 'hm') ~ 'Hourly Max')) %>%
  select(-transformation, -`Train BT R-Sq`, -`Train BT RMSE`)
```

```{r}
full_result_table_fordisp <- base_table %>%
  left_join(log_table %>% select(-n), join_by(date_names, response_base)) %>%
  left_join(base_xgb_result, join_by(date_names == Model, response_base)) %>%
  left_join(log_xgb_result, join_by(date_names == Model, response_base)) %>%
  select(-starts_with('model_response_name'), -starts_with('daterange'), -'date_names') %>%
  select(all_of(c('response_base', 'n', 'adjr2.x', 'p.x', 'adjr2.y', 'bt_adjr2', 'p.y', 'Train R-Sq.x', 'Train RMSE.x', 'Test R-Sq.x', 'Test RMSE.x', 'Train R-Sq.y', 'Train RMSE.y', 'Test R-Sq.y', 'Test BT R-Sq', 'Test RMSE.y', 'Test BT RMSE'))) %>%
  setNames(c('Response','N', 'R2', 'P', 'R2', 'BT R2', 'P',
             c('R2', 'RMSE', 'R2', 'RMSE'), 
             c('R2', 'RMSE', 'R2', 'BT R2', 'RMSE', 'BT RMSE')))
  

full_result_table_kable <- full_result_table_fordisp %>%
  knitr::kable(format = 'latex', digits = 2) %>%
  pack_rows(index = c("Since Feb 2022" = 4, "Disaster Only" = 4, 
                      "Exclude Disaster" = 4, "Everything w D.I" = 4, "Everything w.o D.I" = 4)) %>%
  add_header_above(c(' ' = 7, 'Train' = 2, 'Test' = 2, 'Train' = 2, 'Test' = 4)) %>%
  add_header_above(c(' ' = 2, 'No Transformation' = 2, 'Log-Transformation' = 3, 'No Transformation' = 4, 'Log-Transformation' = 6)) %>%
  add_header_above(c(' ' = 2, 'GAM' = 5, 'XGBoost' = 10))

writeLines(gam_result_table_kable, '../figures/gam_result_table.tex')

full_result_table_fordisp %>%
  knitr::kable(format = 'pipe', digits = 2, table.attr = "style='width:100%;'") %>%
  pack_rows(index = c("Since Feb 2022" = 4, "Disaster Only" = 4, 
                      "Exclude Disaster" = 4, "Everything w D.I" = 4, "Everything w.o D.I" = 4)) %>%
  add_header_above(c(' ' = 7, 'Train' = 2, 'Test' = 2, 'Train' = 2, 'Test' = 4)) %>%
  add_header_above(c(' ' = 2, 'No Transformation' = 2, 'Log-Transformation' = 3, 'No Transformation' = 4, 'Log-Transformation' = 6)) %>%
  add_header_above(c(' ' = 2, 'GAM' = 5, 'XGBoost' = 10)) %>% 
  kable_styling()
```










